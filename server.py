import threading
import asyncio
import json
import os
import time
import argparse
import wave
import base64
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException, Body, UploadFile, File
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse, JSONResponse

# Conditional imports for optional features
try:
    from main import RealTimeASR_SV
    ASR_AVAILABLE = True
except ImportError:
    ASR_AVAILABLE = False
    print("Warning: ASR module not available. Use --no-asr to suppress this warning.")

from llm_client import LLMClient

from chat_manager import ChatManager

# Intelligent Agent imports
try:
    from intelligent_agent import agent_manager
    from trigger_manager import trigger_manager
    AGENT_AVAILABLE = True
except ImportError:
    AGENT_AVAILABLE = False
    print("Warning: Intelligent Agent module not available.")

# Parse command line arguments
parser = argparse.ArgumentParser(description='AST Real-time ASR and LLM Chat Server')
parser.add_argument('--no', action='store_true', help='Skip ALL model initialization (disable ASR, voiceprint, and local agent models)')
parser.add_argument('--no-asr', '--no-voice', action='store_true', help='[DEPRECATED] Use --no instead. Skip ASR and voiceprint model initialization')
parser.add_argument('--host', type=str, default='0.0.0.0', help='Host to bind (default: 0.0.0.0)')
parser.add_argument('--port', type=int, default=8000, help='Port to bind (default: 8000)')
args = parser.parse_args()

# Handle deprecated argument
if args.no_asr:
    print("[âš ï¸  è­¦å‘Š] --no-asr å‚æ•°å·²å¼ƒç”¨ï¼Œè¯·ä½¿ç”¨ --no æ›¿ä»£")
    args.no = True

app = FastAPI()

# Mount static files
app.mount("/static", StaticFiles(directory="static"), name="static")

# --- Config Management ---
CONFIG_FILE = "api_config.json"

def load_config():
    if os.path.exists(CONFIG_FILE):
        with open(CONFIG_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return {"configs": [], "current_config": ""}

def save_config(config):
    with open(CONFIG_FILE, "w", encoding="utf-8") as f:
        json.dump(config, f, indent=4)

# Initialize LLM Client
config_data = load_config()
current_config_name = config_data.get("current_config")
current_config = next((c for c in config_data.get("configs", []) if c["name"] == current_config_name), None)

if current_config:
    llm_client = LLMClient(
        api_key=current_config.get("api_key"),
        base_url=current_config.get("base_url"),
        model=current_config.get("model")
    )
else:
    # Initialize with empty values if no config found
    llm_client = LLMClient(api_key="", base_url="", model="")

# Initialize Chat Manager
chat_manager = ChatManager()

# --- Connection Manager for ASR ---
class ConnectionManager:
    def __init__(self):
        self.active_connections: list[WebSocket] = []

    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)

    def disconnect(self, websocket: WebSocket):
        self.active_connections.remove(websocket)

    async def broadcast(self, message: dict):
        for connection in self.active_connections:
            try:
                await connection.send_json(message)
            except Exception as e:
                print(f"Error sending message: {e}")

manager = ConnectionManager()

# ASR Instance
asr_system = None

def asr_callback(message):
    """Callback function to be called by ASR system when a message is ready"""
    print(f"Callback received: {message}")
    try:
        loop = asyncio.get_event_loop()
        if loop.is_running():
             asyncio.run_coroutine_threadsafe(manager.broadcast(message), loop)
        else:
             pass
    except RuntimeError:
        pass

# We need a reference to the main event loop to schedule tasks from the ASR thread
main_event_loop = None

# --- æ™ºèƒ½åˆ†æå›è°ƒå¤„ç† ---
async def agent_analysis_callback(result, messages, speaker_name):
    """æ™ºèƒ½åˆ†æå®Œæˆå›è°ƒ"""
    try:
        phase1_result = result.get('phase1', {})
        is_needed = phase1_result.get('is', False)
        analysis_id = result.get('analysis_id')
        reason = phase1_result.get('reason', '')
        summary = result.get('analysis_summary')
        count = result.get('analysis_count')
        preview = result.get('analysis_preview')
        model_name = phase1_result.get('model_name')

        summary_label = summary or f"[{speaker_name}]"
        status_text = f"{summary_label} Â· åˆ†æå®Œæˆ"
        if is_needed:
            status_text = f"{summary_label} Â· åŠ©æ‰‹ä»‹å…¥"
        elif reason:
            status_text = f"{summary_label} Â· {reason}"

        # åˆ†æå®Œæˆï¼Œå‘é€ç»“æŸæ¶ˆæ¯åˆ°ASRé¢æ¿
        await manager.broadcast({
            "time": time.strftime("%H:%M:%S"),
            "speaker": "æ™ºèƒ½åˆ†æ",
            "text": status_text,
            "analysis_status": "completed",
            "analysis_need_ai": is_needed,
            "analysis_id": analysis_id,
            "analysis_reason": reason,
            "analysis_summary": summary,
            "analysis_count": count,
            "analysis_preview": preview,
            "analysis_model": model_name
        })

        if is_needed:
            print(f"[æ™ºèƒ½åˆ†æ] âœ… æ£€æµ‹åˆ°éœ€è¦AIå¸®åŠ©åˆ†æï¼Œä¸»äººå…¬: {speaker_name}")

            try:
                # è·å–å½“å‰èŠå¤© ID
                current_chat_id = chat_manager.get_current_chat_id()
                print(f"[æ™ºèƒ½åˆ†æ] å½“å‰èŠå¤©ID: {current_chat_id}")

                # å¦‚æœæ²¡æœ‰å½“å‰èŠå¤©ï¼Œåˆ›å»ºä¸€ä¸ª
                if not current_chat_id:
                    new_chat = chat_manager.create_chat(f"æ™ºèƒ½åˆ†æ - {speaker_name}")
                    current_chat_id = new_chat['id']
                    print(f"[æ™ºèƒ½åˆ†æ] âœ… åˆ›å»ºæ–°èŠå¤©: {current_chat_id}")

                # å‡†å¤‡æ¶ˆæ¯ä¸Šä¸‹æ–‡ï¼ˆæœ€è¿‘çš„ 10 æ¡æ¶ˆæ¯ï¼‰
                recent_messages = messages[-10:] if len(messages) > 10 else messages
                print(f"[æ™ºèƒ½åˆ†æ] å‡†å¤‡å‘é€ {len(recent_messages)} æ¡æ¶ˆæ¯ç»™AI")

                # è·å–åˆ†å‘é…ç½®
                distribution_result = result.get('distribution', {})
                distribution_mode = distribution_result.get('mode', 'single')
                targets = distribution_result.get('targets', [])
                intent_result = distribution_result.get('intent')

                # æ„é€ å‘é€ç»™ä¸‹ä¸€é˜¶æ®µAIçš„æ¶ˆæ¯
                system_prompt = f"ä½ æ˜¯AIåŠ©æ‰‹ï¼Œå¸®åŠ©{speaker_name}æä¾›æŠ€æœ¯æ”¯æŒã€‚"
                if intent_result and intent_result.get("summary_xml"):
                    intent_summary = format_intent_analysis(intent_result)
                    formatted_messages = [
                        {"role": "system", "content": system_prompt + "è¯·æ ¹æ®æ„å›¾è¯†åˆ«ç»“æœç›´æ¥ç»™å‡ºå»ºè®®ã€‚"},
                        {"role": "user", "content": intent_summary}
                    ]
                    print("[æ™ºèƒ½åˆ†æ] ä½¿ç”¨æ„å›¾è¯†åˆ«ç»“æœä½œä¸ºå”¯ä¸€ä¸Šä¸‹æ–‡å‘é€ç»™ä¸‹ä¸€é˜¶æ®µAI")
                else:
                    formatted_messages = [
                        {"role": "system", "content": f"ä½ æ˜¯AIåŠ©æ‰‹ï¼Œå¸®åŠ©{speaker_name}åˆ†æä»¥ä¸‹å¯¹è¯ã€‚{speaker_name}æ˜¯ä¸»äººå…¬ã€‚"}
                    ]
                    for msg in recent_messages:
                        role = 'user' if msg.get('speaker') else 'assistant'
                        content = msg.get('content', '')
                        formatted_messages.append({
                            "role": role,
                            "content": content
                        })
                    print(f"[æ™ºèƒ½åˆ†æ] ä½¿ç”¨å®Œæ•´å¯¹è¯ä¸Šä¸‹æ–‡å‘é€ï¼Œå…± {len(formatted_messages)} æ¡æ¶ˆæ¯")

                print(f"[æ™ºèƒ½åˆ†æ] æ¶ˆæ¯å†…å®¹é¢„è§ˆ:")
                for i, msg in enumerate(formatted_messages):
                    preview = msg['content'][:50]
                    suffix = '...' if len(msg['content']) > 50 else ''
                    print(f"  [{i}] {msg['role']}: {preview}{suffix}")

                # æ ¹æ®åˆ†å‘æ¨¡å¼å†³å®šå¤„ç†æ–¹å¼
                is_multi_llm = (distribution_mode == 'think_tank')

                # æ‰“å°å‘é€å‰çš„è°ƒè¯•ä¿¡æ¯
                print(f"[æ™ºèƒ½åˆ†æ] ğŸ“¤ å‡†å¤‡å‘é€æ¶ˆæ¯åˆ°AI:")
                print(f"  - åˆ†å‘æ¨¡å¼: {'æ™ºå›Šå›¢' if is_multi_llm else 'å•æ¨¡å‹'}")
                print(f"  - èŠå¤©ID: {current_chat_id}")
                print(f"  - æ¶ˆæ¯æ•°é‡: {len(formatted_messages)}")

                # å¦‚æœæœ‰æ™ºå›Šå›¢ç›®æ ‡ï¼Œä½¿ç”¨æ™ºå›Šå›¢æ¨¡å¼
                if is_multi_llm and targets:
                    broadcast_message = {
                        "type": "agent_triggered",
                        "reason": phase1_result.get('reason', 'æ£€æµ‹åˆ°éœ€è¦AIå¸®åŠ©åˆ†æï¼Œå·²å¯åŠ¨æ™ºå›Šå›¢'),
                        "speaker": speaker_name,
                        "messages": formatted_messages,
                        "chat_id": current_chat_id,
                        "is_multi_llm": True,
                        "intent_recognition": intent_result is not None,
                        "intent_data": intent_result
                    }
                    print(f"[æ™ºèƒ½åˆ†æ] ğŸ“¡ å‘é€æ™ºå›Šå›¢è§¦å‘æ¶ˆæ¯...")
                    await llm_manager.broadcast(broadcast_message)
                    print(f"[æ™ºèƒ½åˆ†æ] âœ… ğŸ¤– æ™ºå›Šå›¢å·²è§¦å‘ï¼Œåˆ†å‘åˆ°{len(targets)}ä¸ªç›®æ ‡")
                else:
                    # ä½¿ç”¨å•æ¨¡å‹æ¨¡å¼
                    broadcast_message = {
                        "type": "agent_triggered",
                        "reason": phase1_result.get('reason', 'æ£€æµ‹åˆ°éœ€è¦AIå¸®åŠ©åˆ†æ'),
                        "speaker": speaker_name,
                        "messages": formatted_messages,
                        "chat_id": current_chat_id,
                        "is_multi_llm": False,
                        "intent_recognition": intent_result is not None,
                        "intent_data": intent_result
                    }
                    print(f"[æ™ºèƒ½åˆ†æ] ğŸ“¡ å‘é€å•æ¨¡å‹è§¦å‘æ¶ˆæ¯...")
                    await llm_manager.broadcast(broadcast_message)
                    print(f"[æ™ºèƒ½åˆ†æ] âœ… ğŸ¤– å•æ¨¡å‹æ¨¡å¼å·²è§¦å‘ï¼Œç­‰å¾…AIå›å¤...")
            except Exception as broadcast_error:
                print(f"[æ™ºèƒ½åˆ†æ] âŒ å‘é€æ¶ˆæ¯æ—¶å‡ºé”™: {broadcast_error}")
                import traceback
                traceback.print_exc()
        else:
            print(f"[æ™ºèƒ½åˆ†æ] âŒ æ£€æµ‹åˆ°æ— éœ€AIå¸®åŠ©ï¼Œä¸å‘é€æ¶ˆæ¯")

    except Exception as e:
        print(f"[æ™ºèƒ½åˆ†æ] âŒ å›è°ƒå¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

# --- LLM è¿æ¥ç®¡ç†å™¨ ---
class LLMConnectionManager:
    def __init__(self):
        self.active_connections: list[WebSocket] = []

    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)
        print(f"[LLMè¿æ¥] æ–°è¿æ¥åŠ å…¥ï¼Œå½“å‰æ´»è·ƒè¿æ¥æ•°: {len(self.active_connections)}")

    def disconnect(self, websocket: WebSocket):
        if websocket in self.active_connections:
            self.active_connections.remove(websocket)
            print(f"[LLMè¿æ¥] è¿æ¥æ–­å¼€ï¼Œå½“å‰æ´»è·ƒè¿æ¥æ•°: {len(self.active_connections)}")
        else:
            print(f"[LLMè¿æ¥] å°è¯•æ–­å¼€ä¸å­˜åœ¨çš„è¿æ¥")

    async def broadcast(self, message: dict):
        print(f"[LLMå¹¿æ’­] å¼€å§‹å¹¿æ’­åˆ° {len(self.active_connections)} ä¸ªè¿æ¥")
        print(f"[LLMå¹¿æ’­] æ¶ˆæ¯ç±»å‹: {message.get('type', 'unknown')}")
        print(f"[LLMå¹¿æ’­] æ¶ˆæ¯å†…å®¹: {str(message)[:100]}{'...' if len(str(message)) > 100 else ''}")

        disconnected = []
        for connection in self.active_connections:
            try:
                await connection.send_json(message)
                print(f"[LLMå¹¿æ’­] âœ… æˆåŠŸå‘é€åˆ°è¿æ¥")
            except Exception as e:
                print(f"[LLMå¹¿æ’­] âŒ å¹¿æ’­å¤±è´¥: {e}")
                disconnected.append(connection)

        # ç§»é™¤æ–­å¼€çš„è¿æ¥
        for conn in disconnected:
            if conn in self.active_connections:
                self.active_connections.remove(conn)

        print(f"[LLMå¹¿æ’­] å¹¿æ’­å®Œæˆï¼Œå‰©ä½™ {len(self.active_connections)} ä¸ªæ´»è·ƒè¿æ¥")

llm_manager = LLMConnectionManager()


# --- æ™ºå›Šå›¢è¯·æ±‚å¤„ç†å‡½æ•° ---
async def handle_multi_llm_request(websocket: WebSocket, messages: list, chat_id: str):
    """å¤„ç†æ™ºå›Šå›¢è¯·æ±‚"""
    config_data = load_config()
    active_names = config_data.get("multi_llm_active_names", [])
    configs = config_data.get("configs", [])

    active_configs = [c for c in configs if c["name"] in active_names]

    if not active_configs:
        await websocket.send_json({"type": "error", "content": "æœªé€‰æ‹©ä»»ä½•æ¨¡å‹åŠ å…¥é›†ç¾¤ (è¯·åœ¨è®¾ç½®ä¸­å‹¾é€‰)"})
        return

    # å‘é€è§¦å‘é€šçŸ¥
    await websocket.send_json({
        "type": "agent_notification",
        "content": f"ğŸ¤– æ™ºèƒ½åˆ†æå·²å¯åŠ¨ï¼Œå°†åŒæ—¶è°ƒç”¨ {len(active_configs)} ä¸ªæ¨¡å‹ä¸ºæ‚¨æä¾›å»ºè®®"
    })

    # Prepare tasks
    async def stream_one(conf):
        name = conf["name"]
        try:
            client = LLMClient(conf["api_key"], conf["base_url"], conf["model"])

            # Handle separate system prompt
            current_messages = [m.copy() for m in messages]
            config_prompt = conf.get("system_prompt", "")

            # Check if any tag is selected - if so, disable system prompt
            tags = conf.get("tags", [])
            has_tags = len(tags) > 0

            # åº”ç”¨ System Prompt
            if config_prompt and not has_tags:
                # Replace or insert system prompt
                sys_idx = next((i for i, m in enumerate(current_messages) if m["role"] == "system"), -1)
                if sys_idx != -1:
                    current_messages[sys_idx]["content"] = config_prompt
                else:
                    current_messages.insert(0, {"role": "system", "content": config_prompt})

            # [è°ƒè¯•] æ˜¾ç¤ºå®é™…å‘é€ç»™æ¨¡å‹çš„å®Œæ•´ prompt
            print(f"\n{'='*80}")
            print(f"[è°ƒè¯•] [æ™ºå›Šå›¢] æ­£åœ¨å‘é€è¯·æ±‚åˆ°æ¨¡å‹: {conf.get('model', 'Unknown')} (Stream=True)")
            print(f"{'='*80}")
            print(f"[è°ƒè¯•] [æ™ºå›Šå›¢] æ¨¡å‹åç§°: {name}")
            print(f"[è°ƒè¯•] [æ™ºå›Šå›¢] ä½¿ç”¨ System Prompt: {config_prompt if (config_prompt and not has_tags) else 'å¦'}")
            if has_tags:
                print(f"[è°ƒè¯•] [æ™ºå›Šå›¢] èº«ä»½æ ‡ç­¾: {tags} (System Prompt è¢«ç¦ç”¨)")
            print(f"[è°ƒè¯•] [æ™ºå›Šå›¢] æ¶ˆæ¯æ€»æ•°: {len(current_messages)}")
            print(f"{'-'*80}")
            print("[è°ƒè¯•] [æ™ºå›Šå›¢] å®Œæ•´ Prompt å†…å®¹:")
            print(f"{'-'*80}")
            for i, msg in enumerate(current_messages):
                role = msg.get('role', 'unknown')
                content = msg.get('content', '')
                print(f"\n[æ¶ˆæ¯ {i+1}] è§’è‰²: {role}")
                print(f"[æ¶ˆæ¯ {i+1}] å†…å®¹: {content[:200]}{'...' if len(content) > 200 else ''}")
            print(f"\n{'='*80}\n")

            full_resp = ""
            async for chunk in client.chat_stream(current_messages):
                await websocket.send_json({
                    "type": "chunk",
                    "model": name,
                    "content": chunk
                })
                full_resp += chunk

            await websocket.send_json({"type": "done_one", "model": name})
            return name, full_resp
        except Exception as e:
            err_msg = f"Error: {str(e)}"
            await websocket.send_json({"type": "error", "content": f"[{name}] {err_msg}"})
            return name, f"[Error] {err_msg}"

    # Run all concurrently
    tasks = [stream_one(c) for c in active_configs]
    results = await asyncio.gather(*tasks)

    await websocket.send_json({"type": "done_all"})

    # Save to history
    if chat_id:
        # Append all responses
        for name, text in results:
            messages.append({"role": "assistant", "content": f"**{name}**:\n{text}"})
        chat_manager.update_chat_messages(chat_id, messages)

@app.on_event("startup")
async def startup_event():
    global asr_system, main_event_loop
    main_event_loop = asyncio.get_running_loop()

    # Initialize ASR system only if not skipped
    if not args.no and ASR_AVAILABLE:
        print("[åˆå§‹åŒ–] å¯åŠ¨ ASR ç³»ç»Ÿ...")
        asr_system_initialized = False

        def thread_safe_callback(message):
            # Send to WebSocket clients
            if main_event_loop and main_event_loop.is_running():
                asyncio.run_coroutine_threadsafe(manager.broadcast(message), main_event_loop)

            # Send to trigger manager
            if AGENT_AVAILABLE:
                try:
                    trigger_manager.add_message(message)
                except Exception as e:
                    print(f"[è§¦å‘æœºåˆ¶] å¤„ç†æ¶ˆæ¯å¤±è´¥: {e}")

        try:
            asr_system = RealTimeASR_SV(on_message_callback=thread_safe_callback)
            # Run ASR in a separate thread so it doesn't block FastAPI
            thread = threading.Thread(target=asr_system.run, daemon=True)
            thread.start()
            asr_system_initialized = True
            print("[æˆåŠŸ] ASR ç³»ç»Ÿå·²åœ¨åå°çº¿ç¨‹å¯åŠ¨")
        except Exception as e:
            print(f"[é”™è¯¯] ASR ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
            print("[æç¤º] ä½¿ç”¨ --no å‚æ•°è·³è¿‡æ‰€æœ‰æ¨¡å‹åˆå§‹åŒ–")
    else:
        if args.no:
            print("[é…ç½®] å·²è·³è¿‡æ‰€æœ‰æ¨¡å‹åˆå§‹åŒ– (--no)")
        else:
            print("[é…ç½®] ASR ç³»ç»Ÿä¸å¯ç”¨")

    # Initialize Intelligent Agent
    if AGENT_AVAILABLE and not args.no:
        try:
            # Load agent from config
            config_data = load_config()
            agent_config = config_data.get("agent_config", {})
            agent_model_name = agent_config.get("model_name")

            if agent_model_name:
                # æ£€æŸ¥æ˜¯å¦æ˜¾å¼æŒ‡å®šäº†æ¨¡å‹ç±»å‹
                model_type = agent_config.get('model_type', None)

                if model_type == 'local':
                    # æ˜¾å¼æŒ‡å®šä¸ºæœ¬åœ°æ¨¡å‹
                    print(f"[é…ç½®] ä½¿ç”¨æœ¬åœ°æ¨¡å‹: {agent_model_name}")
                    model_config = {
                        'model_type': 'local',
                        'model': agent_model_name
                    }
                    agent_manager.load_agent(agent_config, model_config)
                    print(f"[æˆåŠŸ] æ™ºèƒ½ Agent å·²åŠ è½½ï¼ˆæœ¬åœ°æ¨¡å‹ï¼‰: {agent_model_name}")
                else:
                    # æœªæ˜¾å¼æŒ‡å®šæˆ–æŒ‡å®šä¸ºAPIï¼Œå…ˆå°è¯•ä»configsä¸­æŸ¥æ‰¾
                    model_config = next(
                        (c for c in config_data.get("configs", []) if c["name"] == agent_model_name),
                        None
                    )

                    if model_config:
                        # åœ¨APIé…ç½®ä¸­æ‰¾åˆ°äº†ï¼Œä½¿ç”¨APIæ¨¡å¼
                        model_config['model_type'] = 'api'
                        agent_manager.load_agent(agent_config, model_config)
                        print(f"[æˆåŠŸ] æ™ºèƒ½ Agent å·²åŠ è½½ï¼ˆAPIæ¨¡å‹ï¼‰: {agent_model_name}")
                    else:
                        # APIé…ç½®ä¸­æ²¡æ‰¾åˆ°ï¼Œä½œä¸ºæœ¬åœ°æ¨¡å‹å¤„ç†
                        print(f"[é…ç½®] åœ¨APIé…ç½®ä¸­æœªæ‰¾åˆ° '{agent_model_name}'ï¼Œä½œä¸ºæœ¬åœ°æ¨¡å‹åŠ è½½")
                        model_config = {
                            'model_type': 'local',
                            'model': agent_model_name
                        }
                        agent_manager.load_agent(agent_config, model_config)
                        print(f"[æˆåŠŸ] æ™ºèƒ½ Agent å·²åŠ è½½ï¼ˆæœ¬åœ°æ¨¡å‹ï¼‰: {agent_model_name}")
            else:
                print("[é…ç½®] æœªé…ç½®æ™ºèƒ½ Agent æ¨¡å‹")

            # æ³¨å†Œæ™ºèƒ½åˆ†æå›è°ƒ
            trigger_manager.add_callback(agent_analysis_callback)
            print("[æˆåŠŸ] æ™ºèƒ½åˆ†æå›è°ƒå·²æ³¨å†Œ")

            # è®¾ç½®trigger managerçš„event loopå¼•ç”¨
            trigger_manager.set_event_loop(main_event_loop)
            print("[æˆåŠŸ] Trigger Manager event loopå·²è®¾ç½®")

            # è®¾ç½®å¹¿æ’­å›è°ƒï¼Œç”¨äºå‘é€WebSocketæ¶ˆæ¯
            async def broadcast_to_asr(message):
                """å‘ASRé¢æ¿å¹¿æ’­æ¶ˆæ¯"""
                await manager.broadcast(message)
            trigger_manager.set_broadcast_callback(broadcast_to_asr)
            print("[æˆåŠŸ] æ™ºèƒ½åˆ†æå¹¿æ’­å›è°ƒå·²è®¾ç½®")

            # åŠ è½½è§¦å‘é˜ˆå€¼å’Œæ¶ˆæ¯ä¸Šé™
            min_characters = agent_config.get("min_characters", 10)
            silence_threshold = agent_config.get("silence_threshold", 2)
            max_messages = agent_config.get("max_messages", 50)
            trigger_manager.set_thresholds(min_characters, silence_threshold)
            trigger_manager.set_max_history(max_messages)
            print(f"[æˆåŠŸ] è§¦å‘å‚æ•°å·²åŠ è½½: {min_characters}å­—, {silence_threshold}ç§’, {max_messages}æ¡æ¶ˆæ¯")

            # åŠ è½½ä¸»äººå…¬é…ç½®
            protagonist = config_data.get("protagonist", "")
            if protagonist:
                trigger_manager.set_protagonist(protagonist)
                print(f"[æˆåŠŸ] ä¸»äººå…¬å·²åŠ è½½: {protagonist}")

        except Exception as e:
            print(f"[é”™è¯¯] æ™ºèƒ½ Agent åˆå§‹åŒ–å¤±è´¥: {e}")
    else:
        if args.no:
            print("[é…ç½®] å·²è·³è¿‡æ™ºèƒ½åˆ†æåˆå§‹åŒ– (--no)")
        elif not AGENT_AVAILABLE:
            print("[é…ç½®] æ™ºèƒ½ Agent æ¨¡å—ä¸å¯ç”¨")

@app.get("/")
async def get():
    with open("static/index.html", "r", encoding="utf-8") as f:
        return HTMLResponse(content=f.read())

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await manager.connect(websocket)

    # ç«‹å³å‘é€ ASR ç³»ç»ŸçŠ¶æ€ç»™å‰ç«¯
    await websocket.send_json({
        "time": "00:00:00",
        "speaker": "ç³»ç»Ÿ",
        "text": "ASR ç³»ç»Ÿæœªåˆå§‹åŒ–" if not asr_system else "ASR ç³»ç»Ÿå·²å°±ç»ª",
        "asr_status": {
            "initialized": asr_system is not None,
            "message": "è¯·ä½¿ç”¨æ­£å¸¸æ¨¡å¼å¯åŠ¨æœåŠ¡å™¨ä»¥å¯ç”¨å®æ—¶è¯­éŸ³è½¬å†™åŠŸèƒ½" if not asr_system else "å®æ—¶è¯­éŸ³è½¬å†™åŠŸèƒ½å·²å¯ç”¨"
        }
    })

    try:
        while True:
            # Keep the connection alive
            await websocket.receive_text()
    except WebSocketDisconnect:
        manager.disconnect(websocket)

# --- LLM Endpoints ---

@app.get("/api/identities")
async def get_identities():
    """Get available identities from data/agent.json"""
    try:
        if os.path.exists("data/agent.json"):
            with open("data/agent.json", "r", encoding="utf-8") as f:
                data = json.load(f)
                return data.get("think_tank_roles", [])
        return []
    except Exception as e:
        print(f"Error loading identities: {e}")
        return []

@app.get("/api/config")
async def get_config():
    return load_config()

@app.post("/api/config")
async def update_config(data: dict = Body(...)):
    """
    Update configuration. 
    Expected data: { "configs": [...], "current_config": "Name" }
    """
    save_config(data)
    
    # Reload LLM Client if current config changed
    new_current_name = data.get("current_config")
    new_config = next((c for c in data.get("configs", []) if c["name"] == new_current_name), None)
    
    if new_config:
        llm_client.update_config(
            api_key=new_config.get("api_key"),
            base_url=new_config.get("base_url"),
            model=new_config.get("model")
        )
    
    return {"status": "success", "message": "Configuration updated"}

@app.post("/api/test_connection")
async def test_connection_endpoint(data: dict = Body(...)):
    """
    Test connection with provided config.
    """
    api_key = data.get("api_key")
    base_url = data.get("base_url")
    model = data.get("model")
    
    if not all([api_key, base_url, model]):
        return {"success": False, "message": "Missing required fields"}
        
    client = LLMClient(api_key=api_key, base_url=base_url, model=model)
    success, message = await client.test_connection()
    return {"success": success, "message": message}

# --- Chat Management Endpoints ---

@app.get("/api/chats")
async def get_chats():
    return {
        "current_chat_id": chat_manager.get_current_chat_id(),
        "chats": chat_manager.get_all_chats()
    }

@app.post("/api/chats")
async def create_chat(data: dict = Body(...)):
    title = data.get("title", "New Chat")
    new_chat = chat_manager.create_chat(title)
    return new_chat

@app.get("/api/chats/{chat_id}")
async def get_chat(chat_id: str):
    chat = chat_manager.get_chat(chat_id)
    if not chat:
        raise HTTPException(status_code=404, detail="Chat not found")
    return chat

@app.delete("/api/chats/{chat_id}")
async def delete_chat(chat_id: str):
    success = chat_manager.delete_chat(chat_id)
    if not success:
        raise HTTPException(status_code=404, detail="Chat not found")
    return {"status": "success"}

@app.post("/api/chats/{chat_id}/clear")
async def clear_chat(chat_id: str):
    success = chat_manager.clear_chat_messages(chat_id)
    if not success:
        raise HTTPException(status_code=404, detail="Chat not found")
    return {"status": "success"}

# --- Intelligent Agent Endpoints ---

@app.get("/api/agent/status")
async def get_agent_status():
    """è·å–æ™ºèƒ½ Agent çŠ¶æ€"""
    if not AGENT_AVAILABLE:
        return {"available": False, "message": "æ™ºèƒ½ Agent æ¨¡å—ä¸å¯ç”¨"}

    config_data = load_config()
    agent_config = config_data.get("agent_config", {})

    return {
        "available": True,
        "enabled": agent_manager.enabled,
        "auto_trigger": agent_manager.auto_trigger,
        "status": trigger_manager.get_status(),
        "config": agent_config
    }

@app.get("/api/agent/roles")
async def get_agent_roles():
    """è·å–æ™ºå›Šå›¢è§’è‰²é…ç½®"""
    try:
        with open("data/agent.json", "r", encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        return {"think_tank_roles": []}
    except json.JSONDecodeError:
        return {"think_tank_roles": []}

@app.post("/api/agent/enable")
async def enable_agent(data: dict = Body(...)):
    """å¯ç”¨/ç¦ç”¨æ™ºèƒ½ Agent"""
    if not AGENT_AVAILABLE:
        raise HTTPException(status_code=503, detail="æ™ºèƒ½ Agent æ¨¡å—ä¸å¯ç”¨")

    enabled = data.get("enabled", True)
    auto_trigger = data.get("auto_trigger", True)

    agent_manager.enabled = enabled
    agent_manager.auto_trigger = auto_trigger
    trigger_manager.set_enabled(enabled)

    # Update config
    config_data = load_config()
    agent_config = config_data.get("agent_config", {})
    agent_config["enabled"] = enabled
    agent_config["auto_trigger"] = auto_trigger
    config_data["agent_config"] = agent_config
    save_config(config_data)

    return {
        "status": "success",
        "enabled": enabled,
        "auto_trigger": auto_trigger
    }

@app.post("/api/agent/config")
async def update_agent_config(data: dict = Body(...)):
    """æ›´æ–°æ™ºèƒ½ Agent é…ç½®"""
    if not AGENT_AVAILABLE:
        raise HTTPException(status_code=503, detail="æ™ºèƒ½ Agent æ¨¡å—ä¸å¯ç”¨")
    print(f"DEBUG: Received update_agent_config data: {data}")
    
    # Update config file
    config_data = load_config()
    agent_config = config_data.get("agent_config", {})
    
    # Only update fields that are present in data
    if "min_characters" in data:
        agent_config["min_characters"] = data["min_characters"]
        
    if "silence_threshold" in data:
        agent_config["silence_threshold"] = data["silence_threshold"]
        
    if "max_messages" in data:
        agent_config["max_messages"] = data["max_messages"]
        
    if "model_name" in data:
        agent_config["model_name"] = data["model_name"]
        
    if "model_type" in data:
        agent_config["model_type"] = data["model_type"]
        
    if "intent_recognition_enabled" in data:
        agent_config["intent_recognition_enabled"] = data["intent_recognition_enabled"]
        
    if "intent_model_name" in data:
        agent_config["intent_model_name"] = data["intent_model_name"]
        
    if "intent_model_type" in data:
        agent_config["intent_model_type"] = data["intent_model_type"]

    # Update trigger manager thresholds if changed
    min_chars = agent_config.get("min_characters", 10)
    silence_thresh = agent_config.get("silence_threshold", 2)
    max_msgs = agent_config.get("max_messages", 50)
    
    trigger_manager.set_thresholds(min_chars, silence_thresh)
    trigger_manager.set_max_history(max_msgs)

    config_data["agent_config"] = agent_config
    save_config(config_data)

    # Reload agent if model changed
    model_name = agent_config.get("model_name")
    if model_name and AGENT_AVAILABLE:
        model_config = next(
            (c for c in config_data.get("configs", []) if c["name"] == model_name),
            None
        )
        if model_config:
            model_config['model_type'] = 'api'
            agent_manager.load_agent(agent_config, model_config)

    return {"status": "success", "config": agent_config}

@app.post("/api/agent/analyze")
async def manual_analyze(data: dict = Body(...)):
    """æ‰‹åŠ¨è§¦å‘æ™ºèƒ½åˆ†ææˆ–æ„å›¾è¯†åˆ«"""
    if not AGENT_AVAILABLE:
        raise HTTPException(status_code=503, detail="æ™ºèƒ½ Agent æ¨¡å—ä¸å¯ç”¨")

    messages = data.get("messages", [])
    speaker_name = data.get("speaker_name", "ç”¨æˆ·")
    request_type = data.get("request_type", "agent_analysis")  # åŒºåˆ†æ˜¯æ™ºèƒ½åˆ†æè¿˜æ˜¯æ„å›¾è¯†åˆ«
    modules_param = data.get("modules")
    print(f"[AgentAPI] æ”¶åˆ° /api/agent/analyze è¯·æ±‚ -> type={request_type}, speaker={speaker_name}, messages={len(messages)}")

    def load_intent_agent(intent_cfg: dict):
        config_data = load_config()
        model_type = intent_cfg.get("model_type", "local")
        model_name = intent_cfg.get("model_name", "Qwen3-0.6B")
        print(f"[AgentAPI] æ„å›¾è¯†åˆ«æ¨¡å‹é…ç½®: type={model_type}, name={model_name}")

        model_config = None
        if model_type == "api":
            model_config = next(
                (c for c in config_data.get("configs", []) if c["name"] == model_name),
                None
            )
            if model_config:
                model_config['model_type'] = 'api'
                print(f"[æ„å›¾è¯†åˆ«] å·²åŠ è½½APIæ¨¡å‹: {model_name}")
            else:
                print(f"[æ„å›¾è¯†åˆ«] æœªæ‰¾åˆ°APIæ¨¡å‹ '{model_name}'ï¼Œé™çº§åˆ°æœ¬åœ°æ¨¡å¼")
                model_type = "local"
                model_name = "Qwen3-0.6B"
                model_config = None

        agent_manager.configure_intent_agent(
            {
                "model_type": model_type,
                "model_name": model_name
            },
            model_config
        )
        if model_type == "local":
            print(f"[æ„å›¾è¯†åˆ«] å·²åŠ è½½æœ¬åœ°æ¨¡å‹: {model_name}")

    def normalize_modules(value):
        if not value:
            return None
        if isinstance(value, str):
            candidates = [value]
        else:
            candidates = list(value)
        normalized = {'analysis': False, 'intent': False, 'think_tank': False}
        for item in candidates:
            name = str(item).strip().lower()
            if name in ("analysis", "smart", "smart_analysis"):
                normalized['analysis'] = True
            elif name in ("intent", "intent_recognition"):
                normalized['intent'] = True
            elif name in ("think_tank", "thinktank", "distribution"):
                normalized['think_tank'] = True
        return normalized if any(normalized.values()) else None

    modules_request = normalize_modules(modules_param)
    if not modules_request and request_type == "intent_recognition":
        modules_request = {'analysis': False, 'intent': True, 'think_tank': False}

    if modules_request:
        print(f"[AgentAPI] modules_request={modules_request}, request_type={request_type}")

        if modules_request['intent']:
            intent_config = data.get("intent_recognition_config", {})
            load_intent_agent(intent_config)

        print(
            "[AgentAPI] è¿è¡Œæ¨¡å— -> "
            f"analysis={modules_request['analysis']} | "
            f"intent={modules_request['intent']} | "
            f"think_tank={modules_request['think_tank']}"
        )

        result = await agent_manager.run_pipeline(
            messages,
            speaker_name,
            use_analysis=modules_request['analysis'],
            use_intent=modules_request['intent'],
            use_think_tank=modules_request['think_tank'],
            bypass_enabled=True,
            force_modules=True
        )

        intent_success = bool(result.get("phase2", {}).get("success")) if modules_request['intent'] else None
        print(
            "[AgentAPI] pipelineå®Œæˆ -> "
            f"phase1_reason={result.get('phase1', {}).get('reason')} | "
            f"intent_success={intent_success}"
        )

        if modules_request['intent'] and not modules_request['analysis']:
            phase2_result = result.get("phase2", {})
            success = bool(phase2_result and phase2_result.get("success"))
            reason = "æ„å›¾è¯†åˆ«å®Œæˆ" if success else phase2_result.get("error", "æ„å›¾è¯†åˆ«å¤±è´¥")
            result["phase1"] = {
                "is": False,
                "reason": reason,
                "confidence": 0.0,
                "intent_only": True,
                "intent_success": success
            }

        return result

    # é»˜è®¤æ‰§è¡Œé˜¶æ®µ1åˆ†æ
    result = await agent_manager.analyze_conversation(messages, speaker_name)
    summary_flag = result.get("is")
    summary_reason = result.get("reason", "")
    print(f"[AgentAPI] åˆ†æå®Œæˆ -> need_ai={summary_flag}, reason={summary_reason}")
    return result

@app.get("/api/protagonist")
async def get_protagonist():
    """è·å–å½“å‰ä¸»äººå…¬é…ç½®"""
    config_data = load_config()
    protagonist = config_data.get("protagonist", "")
    return {"protagonist": protagonist}

@app.post("/api/protagonist")
async def set_protagonist_endpoint(data: dict = Body(...)):
    """è®¾ç½®ä¸»äººå…¬"""
    if not AGENT_AVAILABLE:
        raise HTTPException(status_code=503, detail="æ™ºèƒ½ Agent æ¨¡å—ä¸å¯ç”¨")
    
    protagonist = data.get("protagonist", "").strip()
    
    # æ›´æ–°trigger manager
    trigger_manager.set_protagonist(protagonist)
    
    # ä¿å­˜åˆ°é…ç½®æ–‡ä»¶
    config_data = load_config()
    config_data["protagonist"] = protagonist
    save_config(config_data)
    
    return {"status": "success", "protagonist": protagonist}

@app.post("/api/agent/trigger")
async def trigger_multi_llm(data: dict = Body(...)):
    """æ‰‹åŠ¨è§¦å‘æ™ºå›Šå›¢"""
    messages = data.get("messages", [])
    chat_id = data.get("chat_id")

    # This will be handled by the WebSocket endpoint
    return {
        "status": "triggered",
        "message": "æ™ºå›Šå›¢å·²è§¦å‘",
        "messages": messages,
        "chat_id": chat_id
    }

# --- å£°çº¹ç®¡ç† API ---

@app.get("/api/voiceprints")
async def get_voiceprints():
    """è·å–å£°çº¹åº“åˆ—è¡¨"""
    # å³ä½¿ASRç³»ç»Ÿæœªåˆå§‹åŒ–ï¼Œä¹Ÿèƒ½æŸ¥çœ‹å£°çº¹åˆ—è¡¨
    voiceprint_dir = asr_system.VOICEPRINT_DIR if asr_system else "voiceprints"

    if not os.path.exists(voiceprint_dir):
        return {"voiceprints": []}

    voiceprints = []
    for filename in os.listdir(voiceprint_dir):
        if filename.lower().endswith('.wav'):
            name = os.path.splitext(filename)[0]
            wav_path = os.path.join(voiceprint_dir, filename)
            npy_path = os.path.join(voiceprint_dir, f"{name}.npy")

            # è·å–æ–‡ä»¶å¤§å°
            wav_size = os.path.getsize(wav_path)
            has_embedding = os.path.exists(npy_path)
            embedding_size = os.path.getsize(npy_path) if has_embedding else 0

            # è·å–éŸ³é¢‘æ—¶é•¿ï¼ˆç®€å•ä¼°ç®—ï¼‰
            try:
                import soundfile as sf
                info = sf.info(wav_path)
                duration = round(info.duration, 2)
            except:
                duration = None

            voiceprints.append({
                "name": name,
                "wav_file": filename,
                "wav_size": wav_size,
                "has_embedding": has_embedding,
                "embedding_size": embedding_size,
                "duration": duration,
                "created_time": os.path.getctime(wav_path)
            })

    return {"voiceprints": voiceprints}

@app.post("/api/voiceprints")
async def create_voiceprint(data: dict = Body(...)):
    """å½•åˆ¶å¹¶ä¿å­˜æ–°çš„å£°çº¹"""
    name = data.get("name", "").strip()
    audio_data = data.get("audio_data", "")

    if not name:
        raise HTTPException(status_code=400, detail="è¯·è¾“å…¥è¯´è¯äººå§“å")

    if not audio_data:
        raise HTTPException(status_code=400, detail="ç¼ºå°‘éŸ³é¢‘æ•°æ®")

    # æ£€æŸ¥å§“åæ˜¯å¦å·²å­˜åœ¨
    voiceprint_dir = asr_system.VOICEPRINT_DIR if asr_system else "voiceprints"
    wav_path = os.path.join(voiceprint_dir, f"{name}.wav")
    npy_path = os.path.join(voiceprint_dir, f"{name}.npy")

    if os.path.exists(wav_path):
        raise HTTPException(status_code=400, detail=f"è¯´è¯äºº '{name}' å·²å­˜åœ¨")

    try:
        # è§£ç  base64 éŸ³é¢‘æ•°æ®
        # å‰ç«¯å‘é€çš„æ ¼å¼: "data:audio/wav;base64,<base64_data>"
        if ',' in audio_data:
            header, audio_base64 = audio_data.split(',', 1)
        else:
            audio_base64 = audio_data

        audio_bytes = base64.b64decode(audio_base64)

        # ä¿å­˜ä¸ºä¸´æ—¶ WAV æ–‡ä»¶
        temp_path = os.path.join(voiceprint_dir, f"temp_{name}.wav")
        with open(temp_path, 'wb') as f:
            f.write(audio_bytes)

        # æ£€æŸ¥éŸ³é¢‘æ—¶é•¿
        duration = None
        try:
            import soundfile as sf
            info = sf.info(temp_path)
            duration = info.duration

            if duration < 10:
                os.remove(temp_path)
                raise HTTPException(status_code=400, detail=f"å½•åˆ¶æ—¶é•¿å¤ªçŸ­ ({duration:.1f}ç§’)ï¼Œè‡³å°‘éœ€è¦ 10 ç§’")

            if duration > 40:
                os.remove(temp_path)
                raise HTTPException(status_code=400, detail=f"å½•åˆ¶æ—¶é•¿å¤ªé•¿ ({duration:.1f}ç§’)ï¼Œæœ€å¤š 40 ç§’")
        except Exception as e:
            os.remove(temp_path)
            raise HTTPException(status_code=400, detail=f"éŸ³é¢‘éªŒè¯å¤±è´¥: {str(e)}")

        # å¦‚æœ ASR ç³»ç»Ÿå·²åˆå§‹åŒ–ï¼Œä½¿ç”¨å®Œæ•´æµç¨‹
        if asr_system:
            # è½¬æ¢å¹¶ä¿å­˜ä¸ºæ ‡å‡†æ ¼å¼
            asr_system.check_and_convert_audio(temp_path)
            # é‡å‘½åä¸ºæœ€ç»ˆæ–‡ä»¶å
            os.rename(temp_path, wav_path)

            # è®¡ç®—å¹¶ä¿å­˜åµŒå…¥
            print(f"æ­£åœ¨ä¸º {name} è®¡ç®—å£°çº¹åµŒå…¥...")
            embedding = asr_system.extract_embedding(wav_path)
            if embedding is not None:
                import numpy as np
                np.save(npy_path, embedding)
                print(f"âœ… å£°çº¹åµŒå…¥å·²ä¿å­˜: {name}")

                # é‡æ–°åŠ è½½å£°çº¹åº“
                asr_system.load_voiceprints()

                return {
                    "status": "success",
                    "message": f"å£°çº¹å·²ä¿å­˜: {name}",
                    "name": name,
                    "duration": duration,
                    "embedding_saved": True
                }
            else:
                os.remove(wav_path)
                if os.path.exists(npy_path):
                    os.remove(npy_path)
                raise HTTPException(status_code=500, detail="å£°çº¹åµŒå…¥è®¡ç®—å¤±è´¥")
        else:
            # ASR ç³»ç»Ÿæœªåˆå§‹åŒ–ï¼Œåªä¿å­˜ WAV æ–‡ä»¶
            # åç»­ main.py å¯åŠ¨æ—¶ä¼šè‡ªåŠ¨è½¬æ¢
            os.rename(temp_path, wav_path)
            print(f"âš ï¸  ASR ç³»ç»Ÿæœªåˆå§‹åŒ–ï¼Œå·²ä¿å­˜ WAV æ–‡ä»¶: {name}")
            print(f"ğŸ’¡ æç¤ºï¼šä½¿ç”¨æ­£å¸¸æ¨¡å¼å¯åŠ¨æœåŠ¡å™¨æ—¶ä¼šè‡ªåŠ¨è®¡ç®—å£°çº¹åµŒå…¥")

            return {
                "status": "success",
                "message": f"å£°çº¹å·²ä¿å­˜: {name}ï¼ˆä»…éŸ³é¢‘æ–‡ä»¶ï¼ŒåµŒå…¥å°†åœ¨ä¸‹æ¬¡æ­£å¸¸å¯åŠ¨æ—¶è®¡ç®—ï¼‰",
                "name": name,
                "duration": duration,
                "embedding_saved": False
            }

    except HTTPException:
        raise
    except Exception as e:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        temp_path = os.path.join(voiceprint_dir, f"temp_{name}.wav")
        if os.path.exists(temp_path):
            os.remove(temp_path)
        raise HTTPException(status_code=500, detail=f"ä¿å­˜å¤±è´¥: {str(e)}")

@app.delete("/api/voiceprints/{name}")
async def delete_voiceprint(name: str):
    """åˆ é™¤å£°çº¹"""
    # å³ä½¿ASRç³»ç»Ÿæœªåˆå§‹åŒ–ï¼Œä¹Ÿèƒ½åˆ é™¤å£°çº¹æ–‡ä»¶
    name = name.strip()
    if not name:
        raise HTTPException(status_code=400, detail="è¯·æä¾›è¯´è¯äººå§“å")

    voiceprint_dir = asr_system.VOICEPRINT_DIR if asr_system else "voiceprints"
    wav_path = os.path.join(voiceprint_dir, f"{name}.wav")
    npy_path = os.path.join(voiceprint_dir, f"{name}.npy")

    deleted_files = []

    # åˆ é™¤ WAV æ–‡ä»¶
    if os.path.exists(wav_path):
        os.remove(wav_path)
        deleted_files.append(f"{name}.wav")

    # åˆ é™¤ NPY æ–‡ä»¶
    if os.path.exists(npy_path):
        os.remove(npy_path)
        deleted_files.append(f"{name}.npy")

    if not deleted_files:
        raise HTTPException(status_code=404, detail=f"æœªæ‰¾åˆ°è¯´è¯äºº '{name}' çš„å£°çº¹")

    # åªæœ‰åœ¨ASRç³»ç»Ÿåˆå§‹åŒ–æ—¶æ‰é‡æ–°åŠ è½½å£°çº¹åº“
    if asr_system:
        asr_system.load_voiceprints()

    return {
        "status": "success",
        "message": f"å·²åˆ é™¤å£°çº¹: {name}",
        "deleted_files": deleted_files
    }

@app.post("/api/voiceprints/rebuild")
async def rebuild_voiceprints():
    """é‡æ–°è®¡ç®—æ‰€æœ‰å£°çº¹åµŒå…¥"""
    if not asr_system:
        return {
            "status": "error",
            "detail": "ASR ç³»ç»Ÿæœªåˆå§‹åŒ–ï¼Œæ— æ³•é‡æ–°è®¡ç®—åµŒå…¥ã€‚",
            "message": "è¯·ä½¿ç”¨æ­£å¸¸æ¨¡å¼å¯åŠ¨æœåŠ¡å™¨ï¼ˆä¸ä½¿ç”¨ --no å‚æ•°ï¼‰"
        }

    try:
        asr_system.load_voiceprints()
        return {
            "status": "success",
            "message": "å£°çº¹åµŒå…¥é‡æ–°è®¡ç®—å®Œæˆ",
            "count": len(asr_system.speakers)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"é‡æ–°è®¡ç®—å¤±è´¥: {str(e)}")

@app.get("/api/voiceprint/audio/{name}")
async def get_voiceprint_audio(name: str):
    """è·å–å£°çº¹éŸ³é¢‘æ–‡ä»¶"""
    # å³ä½¿ASRç³»ç»Ÿæœªåˆå§‹åŒ–ï¼Œä¹Ÿèƒ½æä¾›éŸ³é¢‘æ–‡ä»¶
    # è§£ç URLç¼–ç çš„åå­—
    name = name.strip()
    if not name:
        raise HTTPException(status_code=400, detail="è¯·æä¾›è¯´è¯äººå§“å")

    voiceprint_dir = asr_system.VOICEPRINT_DIR if asr_system else "voiceprints"
    wav_path = os.path.join(voiceprint_dir, f"{name}.wav")

    if not os.path.exists(wav_path):
        raise HTTPException(status_code=404, detail=f"æœªæ‰¾åˆ°å£°çº¹æ–‡ä»¶: {name}")

    # è¿”å›éŸ³é¢‘æ–‡ä»¶
    from fastapi.responses import FileResponse
    return FileResponse(
        wav_path,
        media_type='audio/wav',
        filename=f"{name}.wav"
    )

@app.websocket("/ws/llm")
async def llm_websocket(websocket: WebSocket):
    await llm_manager.connect(websocket)

    # Reload config on connection to ensure we have the latest
    current_data = load_config()
    curr_name = current_data.get("current_config")
    curr_conf = next((c for c in current_data.get("configs", []) if c["name"] == curr_name), None)

    if curr_conf:
        llm_client.update_config(
            api_key=curr_conf.get("api_key"),
            base_url=curr_conf.get("base_url"),
            model=curr_conf.get("model")
        )

    try:
        while True:
            data = await websocket.receive_json()

            # å¤„ç†æ™ºèƒ½åˆ†æè§¦å‘æ¶ˆæ¯
            if data.get("type") == "agent_triggered":
                print(f"[æ™ºèƒ½åˆ†æ] âœ… WebSocket æ”¶åˆ°è§¦å‘æ¶ˆæ¯")
                messages = data.get("messages", [])
                chat_id = data.get("chat_id")
                is_multi_llm = data.get("is_multi_llm", False)
                intent_recognition = data.get("intent_recognition", False)

                print(f"[æ™ºèƒ½åˆ†æ] ğŸ“‹ æ¶ˆæ¯è¯¦æƒ…:")
                print(f"  - åˆ†å‘æ¨¡å¼: {'æ™ºå›Šå›¢' if is_multi_llm else 'å•æ¨¡å‹'}")
                print(f"  - æ„å›¾è¯†åˆ«: {'å¼€å¯' if intent_recognition else 'å…³é—­'}")
                print(f"  - æ¶ˆæ¯æ•°é‡: {len(messages)}")
                print(f"  - èŠå¤©ID: {chat_id}")
                print(f"[æ™ºèƒ½åˆ†æ] ğŸ“ æ¶ˆæ¯å†…å®¹é¢„è§ˆ:")
                for i, msg in enumerate(messages):
                    print(f"  [{i}] {msg.get('role', 'unknown')}: {str(msg.get('content', ''))[:50]}{'...' if len(str(msg.get('content', ''))) > 50 else ''}")

                # æ ¹æ®æ¨¡å¼å¤„ç†
                if is_multi_llm:
                    # å¤„ç†æ™ºå›Šå›¢æ¨¡å¼
                    await handle_multi_llm_request(websocket, messages, chat_id)
                else:
                    # å¤„ç†å•æ¨¡å‹æ¨¡å¼
                    await websocket.send_json({
                        "type": "agent_notification",
                        "content": "ğŸ¤– æ™ºèƒ½åˆ†æå·²å¯åŠ¨ï¼Œå°†ä¸ºæ‚¨æä¾›ä¸“ä¸šå»ºè®®"
                    })

                    # ä¿®å¤ï¼šå¤„ç†å½“å‰é…ç½®çš„ System Prompt
                    current_messages = [m.copy() for m in messages]
                    config_prompt = curr_conf.get("system_prompt", "") if curr_conf else ""

                    # æ£€æŸ¥æ˜¯å¦é€‰æ‹©äº†èº«ä»½æ ‡ç­¾ - å¦‚æœé€‰æ‹©äº†ï¼Œç¦ç”¨ system prompt
                    tags = curr_conf.get("tags", []) if curr_conf else []
                    has_tags = len(tags) > 0

                    # åº”ç”¨ System Prompt
                    if config_prompt and not has_tags:
                        # æ›¿æ¢æˆ–æ’å…¥ system prompt
                        sys_idx = next((i for i, m in enumerate(current_messages) if m["role"] == "system"), -1)
                        if sys_idx != -1:
                            current_messages[sys_idx]["content"] = config_prompt
                        else:
                            current_messages.insert(0, {"role": "system", "content": config_prompt})
                    elif has_tags:
                        # å¦‚æœæœ‰èº«ä»½æ ‡ç­¾ï¼Œå°è¯•åŠ è½½å¯¹åº”çš„ Prompt
                        try:
                            agent_json_path = "data/agent.json"
                            if os.path.exists(agent_json_path):
                                with open(agent_json_path, "r", encoding="utf-8") as f:
                                    agent_data = json.load(f)
                                    roles = agent_data.get("think_tank_roles", [])
                                    # æŸ¥æ‰¾åŒ¹é…çš„æ ‡ç­¾ (ä½¿ç”¨ç¬¬ä¸€ä¸ªæ ‡ç­¾)
                                    active_tag = tags[0]
                                    role = next((r for r in roles if r["tag_key"] == active_tag), None)
                                    
                                    if role and role.get("prompt"):
                                        tag_prompt = role["prompt"]
                                        print(f"[æ™ºèƒ½åˆ†æ] åº”ç”¨èº«ä»½æ ‡ç­¾ Prompt: {role['name']}")
                                        
                                        # æ›¿æ¢æˆ–æ’å…¥ system prompt
                                        sys_idx = next((i for i, m in enumerate(current_messages) if m["role"] == "system"), -1)
                                        if sys_idx != -1:
                                            current_messages[sys_idx]["content"] = tag_prompt
                                        else:
                                            current_messages.insert(0, {"role": "system", "content": tag_prompt})
                                    else:
                                        print(f"[æ™ºèƒ½åˆ†æ] æœªæ‰¾åˆ°æ ‡ç­¾ '{active_tag}' çš„ Prompt å®šä¹‰")
                        except Exception as e:
                            print(f"[é”™è¯¯] åŠ è½½èº«ä»½æ ‡ç­¾ Prompt å¤±è´¥: {e}")

                    # [è°ƒè¯•] æ˜¾ç¤ºå®é™…å‘é€ç»™æ¨¡å‹çš„å®Œæ•´ prompt
                    print(f"\n{'='*80}")
                    print(f"[è°ƒè¯•] [æ™ºèƒ½åˆ†æ] æ­£åœ¨å‘é€è¯·æ±‚åˆ°æ¨¡å‹: {curr_conf.get('model', 'Unknown')} (Stream=True)")
                    print(f"{'='*80}")
                    print(f"[è°ƒè¯•] [æ™ºèƒ½åˆ†æ] å½“å‰é…ç½®: {curr_conf.get('name', 'Unknown')}")
                    print(f"[è°ƒè¯•] [æ™ºèƒ½åˆ†æ] ä½¿ç”¨ System Prompt: {config_prompt if (config_prompt and not has_tags) else 'å¦'}")
                    if has_tags:
                        print(f"[è°ƒè¯•] [æ™ºèƒ½åˆ†æ] èº«ä»½æ ‡ç­¾: {tags} (System Prompt è¢«ç¦ç”¨)")
                    print(f"[è°ƒè¯•] [æ™ºèƒ½åˆ†æ] æ¶ˆæ¯æ€»æ•°: {len(current_messages)}")
                    print(f"{'-'*80}")
                    print("[è°ƒè¯•] [æ™ºèƒ½åˆ†æ] å®Œæ•´ Prompt å†…å®¹:")
                    print(f"{'-'*80}")
                    for i, msg in enumerate(current_messages):
                        role = msg.get('role', 'unknown')
                        content = msg.get('content', '')
                        print(f"\n[æ¶ˆæ¯ {i+1}] è§’è‰²: {role}")
                        print(f"[æ¶ˆæ¯ {i+1}] å†…å®¹: {content[:200]}{'...' if len(content) > 200 else ''}")
                    print(f"\n{'='*80}\n")

                    # ç›´æ¥ä½¿ç”¨å½“å‰é…ç½®çš„æ¨¡å‹
                    response_text = ""
                    try:
                        async for chunk in llm_client.chat_stream(current_messages):
                            await websocket.send_json({"type": "chunk", "content": chunk})
                            response_text += chunk

                        await websocket.send_json({"type": "done", "full_text": response_text})

                        # ä¿å­˜åˆ°èŠå¤©å†å²
                        if chat_id:
                            messages.append({"role": "assistant", "content": response_text})
                            chat_manager.update_chat_messages(chat_id, messages)

                    except Exception as e:
                        print(f"å•æ¨¡å‹æµå¼å“åº”é”™è¯¯: {e}")
                        await websocket.send_json({"type": "error", "content": f"æµå¼å“åº”é”™è¯¯: {str(e)}"})

                continue

            # data format: { "messages": [...], "chat_id": "...", "is_multi_llm": bool }
            messages = data.get("messages", [])
            chat_id = data.get("chat_id")
            is_multi_llm = data.get("is_multi_llm", False)

            # Add system prompt if not present or just ensure it's there
            if not messages or messages[0].get("role") != "system":
                 messages.insert(0, {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªAiåŠ©æ‰‹å¸®åŠ©ç”¨æˆ·ï¼Œå¹¶ä¸”åˆ†æèŠå¤©è®°å½•"})

            if is_multi_llm:
                # --- Multi-LLM Mode ---
                config_data = load_config()
                active_names = config_data.get("multi_llm_active_names", [])
                configs = config_data.get("configs", [])
                
                active_configs = [c for c in configs if c["name"] in active_names]
                
                if not active_configs:
                     await websocket.send_json({"type": "error", "content": "æœªé€‰æ‹©ä»»ä½•æ¨¡å‹åŠ å…¥é›†ç¾¤ (è¯·åœ¨è®¾ç½®ä¸­å‹¾é€‰)"})
                     continue
                
                # Prepare tasks
                async def stream_one(conf):
                    name = conf["name"]
                    try:
                        client = LLMClient(conf["api_key"], conf["base_url"], conf["model"])

                        # Handle separate system prompt
                        current_messages = [m.copy() for m in messages] # Deep copyish
                        config_prompt = conf.get("system_prompt", "")

                        # Check if any tag is selected - if so, disable system prompt
                        tags = conf.get("tags", [])
                        has_tags = len(tags) > 0

                        # åº”ç”¨ System Prompt
                        if config_prompt and not has_tags:
                            # Replace or insert system prompt
                            sys_idx = next((i for i, m in enumerate(current_messages) if m["role"] == "system"), -1)
                            if sys_idx != -1:
                                current_messages[sys_idx]["content"] = config_prompt
                            else:
                                current_messages.insert(0, {"role": "system", "content": config_prompt})

                        # [è°ƒè¯•] æ˜¾ç¤ºå®é™…å‘é€ç»™æ¨¡å‹çš„å®Œæ•´ prompt
                        print(f"\n{'='*80}")
                        print(f"[è°ƒè¯•] æ­£åœ¨å‘é€è¯·æ±‚åˆ°æ¨¡å‹: {conf.get('model', 'Unknown')} (Stream=True)")
                        print(f"{'='*80}")
                        print(f"[è°ƒè¯•] æ¨¡å‹åç§°: {name}")
                        print(f"[è°ƒè¯•] ä½¿ç”¨ System Prompt: {config_prompt if (config_prompt and not has_tags) else 'å¦'}")
                        if has_tags:
                            print(f"[è°ƒè¯•] èº«ä»½æ ‡ç­¾: {tags} (System Prompt è¢«ç¦ç”¨)")
                        print(f"[è°ƒè¯•] æ¶ˆæ¯æ€»æ•°: {len(current_messages)}")
                        print(f"{'-'*80}")
                        print("[è°ƒè¯•] å®Œæ•´ Prompt å†…å®¹:")
                        print(f"{'-'*80}")
                        for i, msg in enumerate(current_messages):
                            role = msg.get('role', 'unknown')
                            content = msg.get('content', '')
                            print(f"\n[æ¶ˆæ¯ {i+1}] è§’è‰²: {role}")
                            print(f"[æ¶ˆæ¯ {i+1}] å†…å®¹: {content[:200]}{'...' if len(content) > 200 else ''}")
                        print(f"\n{'='*80}\n")

                        full_resp = ""
                        async for chunk in client.chat_stream(current_messages):
                            await websocket.send_json({
                                "type": "chunk",
                                "model": name,
                                "content": chunk
                            })
                            full_resp += chunk
                        
                        await websocket.send_json({"type": "done_one", "model": name})
                        return name, full_resp
                    except Exception as e:
                        err_msg = f"Error: {str(e)}"
                        await websocket.send_json({"type": "error", "content": f"[{name}] {err_msg}"})
                        return name, f"[Error] {err_msg}"

                # Run all concurrently
                tasks = [stream_one(c) for c in active_configs]
                results = await asyncio.gather(*tasks)
                
                await websocket.send_json({"type": "done_all"})
                
                # Save to history
                if chat_id:
                    # Append all responses
                    for name, text in results:
                        messages.append({"role": "assistant", "content": f"**{name}**:\n{text}"})
                    chat_manager.update_chat_messages(chat_id, messages)

            else:
                # --- Single LLM Mode (Original Logic) ---
                response_text = ""
                try:
                    # Check if client is ready
                    if not llm_client.client:
                         await websocket.send_json({"type": "error", "content": "LLM Client not initialized. Please check settings."})
                         continue

                    # ä¿®å¤ï¼šå¤„ç†å½“å‰é…ç½®çš„ System Prompt
                    current_messages = [m.copy() for m in messages]
                    config_prompt = curr_conf.get("system_prompt", "") if curr_conf else ""

                    # æ£€æŸ¥æ˜¯å¦é€‰æ‹©äº†èº«ä»½æ ‡ç­¾ - å¦‚æœé€‰æ‹©äº†ï¼Œç¦ç”¨ system prompt
                    tags = curr_conf.get("tags", []) if curr_conf else []
                    has_tags = len(tags) > 0

                    # åº”ç”¨ System Prompt
                    if config_prompt and not has_tags:
                        # æ›¿æ¢æˆ–æ’å…¥ system prompt
                        sys_idx = next((i for i, m in enumerate(current_messages) if m["role"] == "system"), -1)
                        if sys_idx != -1:
                            current_messages[sys_idx]["content"] = config_prompt
                        else:
                            current_messages.insert(0, {"role": "system", "content": config_prompt})

                    # [è°ƒè¯•] æ˜¾ç¤ºå®é™…å‘é€ç»™æ¨¡å‹çš„å®Œæ•´ prompt
                    print(f"\n{'='*80}")
                    print(f"[è°ƒè¯•] æ­£åœ¨å‘é€è¯·æ±‚åˆ°æ¨¡å‹: {curr_conf.get('model', 'Unknown')} (Stream=True)")
                    print(f"{'='*80}")
                    print(f"[è°ƒè¯•] å½“å‰é…ç½®: {curr_conf.get('name', 'Unknown')}")
                    print(f"[è°ƒè¯•] ä½¿ç”¨ System Prompt: {config_prompt if (config_prompt and not has_tags) else 'å¦'}")
                    if has_tags:
                        print(f"[è°ƒè¯•] èº«ä»½æ ‡ç­¾: {tags} (System Prompt è¢«ç¦ç”¨)")
                    print(f"[è°ƒè¯•] æ¶ˆæ¯æ€»æ•°: {len(current_messages)}")
                    print(f"{'-'*80}")
                    print("[è°ƒè¯•] å®Œæ•´ Prompt å†…å®¹:")
                    print(f"{'-'*80}")
                    for i, msg in enumerate(current_messages):
                        role = msg.get('role', 'unknown')
                        content = msg.get('content', '')
                        print(f"\n[æ¶ˆæ¯ {i+1}] è§’è‰²: {role}")
                        print(f"[æ¶ˆæ¯ {i+1}] å†…å®¹: {content[:200]}{'...' if len(content) > 200 else ''}")
                    print(f"\n{'='*80}\n")

                    async for chunk in llm_client.chat_stream(current_messages):
                        await websocket.send_json({"type": "chunk", "content": chunk})
                        response_text += chunk

                    await websocket.send_json({"type": "done", "full_text": response_text})

                    # Save to chat history if chat_id is provided
                    if chat_id:
                        messages.append({"role": "assistant", "content": response_text})
                        chat_manager.update_chat_messages(chat_id, messages)

                except Exception as e:
                    print(f"LLM Stream Error: {e}")
                    import traceback
                    traceback.print_exc()
                    try:
                        await websocket.send_json({"type": "error", "content": f"Stream Error: {str(e)}"})
                    except Exception as send_error:
                        print(f"å‘é€é”™è¯¯æ¶ˆæ¯å¤±è´¥: {send_error}")

    except WebSocketDisconnect:
        print("LLM WebSocket disconnected")
        llm_manager.disconnect(websocket)
    except Exception as e:
        print(f"LLM WebSocket Fatal Error: {e}")
        import traceback
        traceback.print_exc()
        try:
            llm_manager.disconnect(websocket)
        except Exception as disconnect_error:
            print(f"æ–­å¼€è¿æ¥å¤±è´¥: {disconnect_error}")

if __name__ == "__main__":
    import uvicorn

    # Print startup banner
    print("=" * 60)
    print("ğŸš€ AST å®æ—¶è¯­éŸ³è½¬æ–‡æœ¬ä¸å¤§æ¨¡å‹åˆ†æç³»ç»Ÿ")
    print("=" * 60)
    print(f"[é…ç½®] ASR ç³»ç»Ÿ: {'âœ… å¯ç”¨' if not args.no else 'âŒ ç¦ç”¨ (--no)'}")
    print(f"[é…ç½®] LLM å®¢æˆ·ç«¯: âœ… å¯ç”¨")
    print(f"[é…ç½®] æœåŠ¡åœ°å€: http://{args.host}:{args.port}")
    print("=" * 60)
    print("")

    uvicorn.run(app, host=args.host, port=args.port)
def format_intent_analysis(intent_result: dict) -> str:
    """å°†æ„å›¾è¯†åˆ«ç»“æœæ ¼å¼åŒ–ä¸ºç³»ç»Ÿæ¶ˆæ¯"""
    summary_xml = intent_result.get("summary_xml", "")
    if not summary_xml:
        return "ã€æ„å›¾è¯†åˆ«ã€‘æœªç”Ÿæˆç»“æ„åŒ–ç»“æœ"

    def _extract(tag):
        import re
        match = re.search(rf"<{tag}>([\s\S]*?)</{tag}>", summary_xml, re.IGNORECASE)
        return match.group(1).strip() if match else ""

    summary = _extract("summary")
    question = _extract("true_question")
    steps = re.findall(r"<step>([\s\S]*?)</step>", summary_xml, re.IGNORECASE)
    steps = [s.strip() for s in steps if s.strip()]

    parts = ["ã€Leader Agent æ„å›¾åˆ†æã€‘"]
    if summary:
        parts.append(f"æ„å›¾æ€»ç»“ï¼š{summary}")
    if question:
        parts.append(f"çœŸå®é—®é¢˜ï¼š{question}")
    if steps:
        parts.append("ä¸‹ä¸€æ­¥è¡ŒåŠ¨ï¼š")
        parts.extend(f"- {step}" for step in steps)
    return "\n".join(parts)
