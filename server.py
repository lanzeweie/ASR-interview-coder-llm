import threading
import asyncio
import json
import os
import argparse
import wave
import base64
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException, Body, UploadFile, File
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse, JSONResponse

# Conditional imports for optional features
try:
    from main import RealTimeASR_SV
    ASR_AVAILABLE = True
except ImportError:
    ASR_AVAILABLE = False
    print("Warning: ASR module not available. Use --no-asr to suppress this warning.")

from llm_client import LLMClient

from chat_manager import ChatManager

# Intelligent Agent imports
try:
    from intelligent_agent import agent_manager
    from trigger_manager import trigger_manager
    AGENT_AVAILABLE = True
except ImportError:
    AGENT_AVAILABLE = False
    print("Warning: Intelligent Agent module not available.")

# Parse command line arguments
parser = argparse.ArgumentParser(description='AST Real-time ASR and LLM Chat Server')
parser.add_argument('--no-asr', '--no', action='store_true', help='Skip ASR model initialization (skip audio and ASR)')
parser.add_argument('--host', type=str, default='0.0.0.0', help='Host to bind (default: 0.0.0.0)')
parser.add_argument('--port', type=int, default=8000, help='Port to bind (default: 8000)')
args = parser.parse_args()

app = FastAPI()

# Mount static files
app.mount("/static", StaticFiles(directory="static"), name="static")

# --- Config Management ---
CONFIG_FILE = "api_config.json"

def load_config():
    if os.path.exists(CONFIG_FILE):
        with open(CONFIG_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return {"configs": [], "current_config": ""}

def save_config(config):
    with open(CONFIG_FILE, "w", encoding="utf-8") as f:
        json.dump(config, f, indent=4)

# Initialize LLM Client
config_data = load_config()
current_config_name = config_data.get("current_config")
current_config = next((c for c in config_data.get("configs", []) if c["name"] == current_config_name), None)

if current_config:
    llm_client = LLMClient(
        api_key=current_config.get("api_key"),
        base_url=current_config.get("base_url"),
        model=current_config.get("model")
    )
else:
    # Initialize with empty values if no config found
    llm_client = LLMClient(api_key="", base_url="", model="")

# Initialize Chat Manager
chat_manager = ChatManager()

# --- Connection Manager for ASR ---
class ConnectionManager:
    def __init__(self):
        self.active_connections: list[WebSocket] = []

    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)

    def disconnect(self, websocket: WebSocket):
        self.active_connections.remove(websocket)

    async def broadcast(self, message: dict):
        for connection in self.active_connections:
            try:
                await connection.send_json(message)
            except Exception as e:
                print(f"Error sending message: {e}")

manager = ConnectionManager()

# ASR Instance
asr_system = None

def asr_callback(message):
    """Callback function to be called by ASR system when a message is ready"""
    print(f"Callback received: {message}")
    try:
        loop = asyncio.get_event_loop()
        if loop.is_running():
             asyncio.run_coroutine_threadsafe(manager.broadcast(message), loop)
        else:
             pass
    except RuntimeError:
        pass

# We need a reference to the main event loop to schedule tasks from the ASR thread
main_event_loop = None

# --- æ™ºèƒ½åˆ†æå›è°ƒå¤„ç† ---
async def agent_analysis_callback(result, messages, speaker_name):
    """æ™ºèƒ½åˆ†æå®Œæˆå›è°ƒ"""
    try:
        is_needed = result.get('is', False)

        if is_needed:
            print(f"[æ™ºèƒ½åˆ†æ] æ£€æµ‹åˆ°éœ€è¦å¤šæ¨¡å‹å»ºè®®ï¼Œä¸»äººå…¬: {speaker_name}")

            # è·å–å½“å‰èŠå¤© ID
            current_chat_id = chat_manager.get_current_chat_id()

            # å¦‚æœæ²¡æœ‰å½“å‰èŠå¤©ï¼Œåˆ›å»ºä¸€ä¸ª
            if not current_chat_id:
                new_chat = chat_manager.create_chat(f"æ™ºèƒ½åˆ†æ - {speaker_name}")
                current_chat_id = new_chat['id']

            # å‡†å¤‡æ¶ˆæ¯ä¸Šä¸‹æ–‡ï¼ˆæœ€è¿‘çš„ 10 æ¡æ¶ˆæ¯ï¼‰
            recent_messages = messages[-10:] if len(messages) > 10 else messages

            # æ·»åŠ ç³»ç»Ÿæç¤º
            formatted_messages = [
                {"role": "system", "content": f"ä½ æ˜¯AIåŠ©æ‰‹ï¼Œå¸®åŠ©{speaker_name}åˆ†æä»¥ä¸‹å¯¹è¯ã€‚{speaker_name}æ˜¯ä¸»äººå…¬ã€‚"}
            ]

            # æ·»åŠ å¯¹è¯å†å²
            for msg in recent_messages:
                role = 'user' if msg.get('speaker') else 'assistant'
                formatted_messages.append({
                    "role": role,
                    "content": msg.get('content', '')
                })

            # æ¨é€åˆ°æ‰€æœ‰ LLM WebSocket å®¢æˆ·ç«¯
            await llm_manager.broadcast({
                "type": "agent_triggered",
                "reason": result.get('reason', 'æ™ºèƒ½åˆ†æå»ºè®®'),
                "speaker": speaker_name,
                "messages": formatted_messages,
                "chat_id": current_chat_id,
                "is_multi_llm": True
            })

            print(f"[æ™ºèƒ½åˆ†æ] å¤šæ¨¡å‹å…±è¯å·²è§¦å‘")

    except Exception as e:
        print(f"[æ™ºèƒ½åˆ†æ] å›è°ƒå¤„ç†å¤±è´¥: {e}")

# --- LLM è¿æ¥ç®¡ç†å™¨ ---
class LLMConnectionManager:
    def __init__(self):
        self.active_connections: list[WebSocket] = []

    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)

    def disconnect(self, websocket: WebSocket):
        self.active_connections.remove(websocket)

    async def broadcast(self, message: dict):
        for connection in self.active_connections:
            try:
                await connection.send_json(message)
            except Exception as e:
                print(f"LLM å¹¿æ’­å¤±è´¥: {e}")

llm_manager = LLMConnectionManager()

# --- å¤šæ¨¡å‹è¯·æ±‚å¤„ç†å‡½æ•° ---
async def handle_multi_llm_request(websocket: WebSocket, messages: list, chat_id: str):
    """å¤„ç†å¤šæ¨¡å‹å…±è¯è¯·æ±‚"""
    config_data = load_config()
    active_names = config_data.get("multi_llm_active_names", [])
    configs = config_data.get("configs", [])

    active_configs = [c for c in configs if c["name"] in active_names]

    if not active_configs:
        await websocket.send_json({"type": "error", "content": "æœªé€‰æ‹©ä»»ä½•æ¨¡å‹åŠ å…¥é›†ç¾¤ (è¯·åœ¨è®¾ç½®ä¸­å‹¾é€‰)"})
        return

    # å‘é€è§¦å‘é€šçŸ¥
    await websocket.send_json({
        "type": "agent_notification",
        "content": f"ğŸ¤– æ™ºèƒ½åˆ†æå·²å¯åŠ¨ï¼Œå°†åŒæ—¶è°ƒç”¨ {len(active_configs)} ä¸ªæ¨¡å‹ä¸ºæ‚¨æä¾›å»ºè®®"
    })

    # Prepare tasks
    async def stream_one(conf):
        name = conf["name"]
        try:
            client = LLMClient(conf["api_key"], conf["base_url"], conf["model"])

            # Handle separate system prompt
            current_messages = [m.copy() for m in messages]
            config_prompt = conf.get("system_prompt", "")

            if config_prompt:
                # Replace or insert system prompt
                sys_idx = next((i for i, m in enumerate(current_messages) if m["role"] == "system"), -1)
                if sys_idx != -1:
                    current_messages[sys_idx]["content"] = config_prompt
                else:
                    current_messages.insert(0, {"role": "system", "content": config_prompt})

            full_resp = ""
            async for chunk in client.chat_stream(current_messages):
                await websocket.send_json({
                    "type": "chunk",
                    "model": name,
                    "content": chunk
                })
                full_resp += chunk

            await websocket.send_json({"type": "done_one", "model": name})
            return name, full_resp
        except Exception as e:
            err_msg = f"Error: {str(e)}"
            await websocket.send_json({"type": "error", "content": f"[{name}] {err_msg}"})
            return name, f"[Error] {err_msg}"

    # Run all concurrently
    tasks = [stream_one(c) for c in active_configs]
    results = await asyncio.gather(*tasks)

    await websocket.send_json({"type": "done_all"})

    # Save to history
    if chat_id:
        # Append all responses
        for name, text in results:
            messages.append({"role": "assistant", "content": f"**{name}**:\n{text}"})
        chat_manager.update_chat_messages(chat_id, messages)

@app.on_event("startup")
async def startup_event():
    global asr_system, main_event_loop
    main_event_loop = asyncio.get_running_loop()

    # Initialize ASR system only if not skipped
    if not args.no_asr and ASR_AVAILABLE:
        print("[åˆå§‹åŒ–] å¯åŠ¨ ASR ç³»ç»Ÿ...")
        asr_system_initialized = False

        def thread_safe_callback(message):
            # Send to WebSocket clients
            if main_event_loop and main_event_loop.is_running():
                asyncio.run_coroutine_threadsafe(manager.broadcast(message), main_event_loop)

            # Send to trigger manager
            if AGENT_AVAILABLE:
                try:
                    trigger_manager.add_message(message)
                except Exception as e:
                    print(f"[è§¦å‘æœºåˆ¶] å¤„ç†æ¶ˆæ¯å¤±è´¥: {e}")

        try:
            asr_system = RealTimeASR_SV(on_message_callback=thread_safe_callback)
            # Run ASR in a separate thread so it doesn't block FastAPI
            thread = threading.Thread(target=asr_system.run, daemon=True)
            thread.start()
            asr_system_initialized = True
            print("[æˆåŠŸ] ASR ç³»ç»Ÿå·²åœ¨åå°çº¿ç¨‹å¯åŠ¨")
        except Exception as e:
            print(f"[é”™è¯¯] ASR ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
            print("[æç¤º] ä½¿ç”¨ --no-asr å‚æ•°è·³è¿‡ ASR åˆå§‹åŒ–")
    else:
        if args.no_asr:
            print("[é…ç½®] å·²è·³è¿‡ ASR ç³»ç»Ÿåˆå§‹åŒ– (--no-asr)")
        else:
            print("[é…ç½®] ASR ç³»ç»Ÿä¸å¯ç”¨")

    # Initialize Intelligent Agent
    if AGENT_AVAILABLE:
        try:
            # Load agent from config
            config_data = load_config()
            agent_config = config_data.get("agent_config", {})
            agent_model_name = agent_config.get("model_name")

            if agent_model_name:
                # æ£€æŸ¥æ˜¯å¦æ˜¾å¼æŒ‡å®šäº†æ¨¡å‹ç±»å‹
                model_type = agent_config.get('model_type', None)
                
                if model_type == 'local':
                    # æ˜¾å¼æŒ‡å®šä¸ºæœ¬åœ°æ¨¡å‹
                    print(f"[é…ç½®] ä½¿ç”¨æœ¬åœ°æ¨¡å‹: {agent_model_name}")
                    model_config = {
                        'model_type': 'local',
                        'model': agent_model_name
                    }
                    agent_manager.load_agent(agent_config, model_config)
                    print(f"[æˆåŠŸ] æ™ºèƒ½ Agent å·²åŠ è½½ï¼ˆæœ¬åœ°æ¨¡å‹ï¼‰: {agent_model_name}")
                else:
                    # æœªæ˜¾å¼æŒ‡å®šæˆ–æŒ‡å®šä¸ºAPIï¼Œå…ˆå°è¯•ä»configsä¸­æŸ¥æ‰¾
                    model_config = next(
                        (c for c in config_data.get("configs", []) if c["name"] == agent_model_name),
                        None
                    )

                    if model_config:
                        # åœ¨APIé…ç½®ä¸­æ‰¾åˆ°äº†ï¼Œä½¿ç”¨APIæ¨¡å¼
                        model_config['model_type'] = 'api'
                        agent_manager.load_agent(agent_config, model_config)
                        print(f"[æˆåŠŸ] æ™ºèƒ½ Agent å·²åŠ è½½ï¼ˆAPIæ¨¡å‹ï¼‰: {agent_model_name}")
                    else:
                        # APIé…ç½®ä¸­æ²¡æ‰¾åˆ°ï¼Œä½œä¸ºæœ¬åœ°æ¨¡å‹å¤„ç†
                        print(f"[é…ç½®] åœ¨APIé…ç½®ä¸­æœªæ‰¾åˆ° '{agent_model_name}'ï¼Œä½œä¸ºæœ¬åœ°æ¨¡å‹åŠ è½½")
                        model_config = {
                            'model_type': 'local',
                            'model': agent_model_name
                        }
                        agent_manager.load_agent(agent_config, model_config)
                        print(f"[æˆåŠŸ] æ™ºèƒ½ Agent å·²åŠ è½½ï¼ˆæœ¬åœ°æ¨¡å‹ï¼‰: {agent_model_name}")
            else:
                print("[é…ç½®] æœªé…ç½®æ™ºèƒ½ Agent æ¨¡å‹")

            # æ³¨å†Œæ™ºèƒ½åˆ†æå›è°ƒ
            trigger_manager.add_callback(agent_analysis_callback)
            print("[æˆåŠŸ] æ™ºèƒ½åˆ†æå›è°ƒå·²æ³¨å†Œ")

            # è®¾ç½®trigger managerçš„event loopå¼•ç”¨
            trigger_manager.set_event_loop(main_event_loop)
            print("[æˆåŠŸ] Trigger Manager event loopå·²è®¾ç½®")

            # åŠ è½½ä¸»äººå…¬é…ç½®
            protagonist = config_data.get("protagonist", "")
            if protagonist:
                trigger_manager.set_protagonist(protagonist)
                print(f"[æˆåŠŸ] ä¸»äººå…¬å·²åŠ è½½: {protagonist}")

        except Exception as e:
            print(f"[é”™è¯¯] æ™ºèƒ½ Agent åˆå§‹åŒ–å¤±è´¥: {e}")
    else:
        print("[é…ç½®] æ™ºèƒ½ Agent æ¨¡å—ä¸å¯ç”¨")

@app.get("/")
async def get():
    with open("static/index.html", "r", encoding="utf-8") as f:
        return HTMLResponse(content=f.read())

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await manager.connect(websocket)

    # ç«‹å³å‘é€ ASR ç³»ç»ŸçŠ¶æ€ç»™å‰ç«¯
    await websocket.send_json({
        "time": "00:00:00",
        "speaker": "ç³»ç»Ÿ",
        "text": "ASR ç³»ç»Ÿæœªåˆå§‹åŒ–" if not asr_system else "ASR ç³»ç»Ÿå·²å°±ç»ª",
        "asr_status": {
            "initialized": asr_system is not None,
            "message": "è¯·ä½¿ç”¨æ­£å¸¸æ¨¡å¼å¯åŠ¨æœåŠ¡å™¨ä»¥å¯ç”¨å®æ—¶è¯­éŸ³è½¬å†™åŠŸèƒ½" if not asr_system else "å®æ—¶è¯­éŸ³è½¬å†™åŠŸèƒ½å·²å¯ç”¨"
        }
    })

    try:
        while True:
            # Keep the connection alive
            await websocket.receive_text()
    except WebSocketDisconnect:
        manager.disconnect(websocket)

# --- LLM Endpoints ---

@app.get("/api/config")
async def get_config():
    return load_config()

@app.post("/api/config")
async def update_config(data: dict = Body(...)):
    """
    Update configuration. 
    Expected data: { "configs": [...], "current_config": "Name" }
    """
    save_config(data)
    
    # Reload LLM Client if current config changed
    new_current_name = data.get("current_config")
    new_config = next((c for c in data.get("configs", []) if c["name"] == new_current_name), None)
    
    if new_config:
        llm_client.update_config(
            api_key=new_config.get("api_key"),
            base_url=new_config.get("base_url"),
            model=new_config.get("model")
        )
    
    return {"status": "success", "message": "Configuration updated"}

@app.post("/api/test_connection")
async def test_connection_endpoint(data: dict = Body(...)):
    """
    Test connection with provided config.
    """
    api_key = data.get("api_key")
    base_url = data.get("base_url")
    model = data.get("model")
    
    if not all([api_key, base_url, model]):
        return {"success": False, "message": "Missing required fields"}
        
    client = LLMClient(api_key=api_key, base_url=base_url, model=model)
    success, message = await client.test_connection()
    return {"success": success, "message": message}

# --- Chat Management Endpoints ---

@app.get("/api/chats")
async def get_chats():
    return {
        "current_chat_id": chat_manager.get_current_chat_id(),
        "chats": chat_manager.get_all_chats()
    }

@app.post("/api/chats")
async def create_chat(data: dict = Body(...)):
    title = data.get("title", "New Chat")
    new_chat = chat_manager.create_chat(title)
    return new_chat

@app.get("/api/chats/{chat_id}")
async def get_chat(chat_id: str):
    chat = chat_manager.get_chat(chat_id)
    if not chat:
        raise HTTPException(status_code=404, detail="Chat not found")
    return chat

@app.delete("/api/chats/{chat_id}")
async def delete_chat(chat_id: str):
    success = chat_manager.delete_chat(chat_id)
    if not success:
        raise HTTPException(status_code=404, detail="Chat not found")
    return {"status": "success"}

@app.post("/api/chats/{chat_id}/clear")
async def clear_chat(chat_id: str):
    success = chat_manager.clear_chat_messages(chat_id)
    if not success:
        raise HTTPException(status_code=404, detail="Chat not found")
    return {"status": "success"}

# --- Intelligent Agent Endpoints ---

@app.get("/api/agent/status")
async def get_agent_status():
    """è·å–æ™ºèƒ½ Agent çŠ¶æ€"""
    if not AGENT_AVAILABLE:
        return {"available": False, "message": "æ™ºèƒ½ Agent æ¨¡å—ä¸å¯ç”¨"}

    config_data = load_config()
    agent_config = config_data.get("agent_config", {})

    return {
        "available": True,
        "enabled": agent_manager.enabled,
        "auto_trigger": agent_manager.auto_trigger,
        "status": trigger_manager.get_status(),
        "config": agent_config
    }

@app.post("/api/agent/enable")
async def enable_agent(data: dict = Body(...)):
    """å¯ç”¨/ç¦ç”¨æ™ºèƒ½ Agent"""
    if not AGENT_AVAILABLE:
        raise HTTPException(status_code=503, detail="æ™ºèƒ½ Agent æ¨¡å—ä¸å¯ç”¨")

    enabled = data.get("enabled", True)
    auto_trigger = data.get("auto_trigger", True)

    agent_manager.enabled = enabled
    agent_manager.auto_trigger = auto_trigger
    trigger_manager.set_enabled(enabled)

    # Update config
    config_data = load_config()
    agent_config = config_data.get("agent_config", {})
    agent_config["enabled"] = enabled
    agent_config["auto_trigger"] = auto_trigger
    config_data["agent_config"] = agent_config
    save_config(config_data)

    return {
        "status": "success",
        "enabled": enabled,
        "auto_trigger": auto_trigger
    }

@app.post("/api/agent/config")
async def update_agent_config(data: dict = Body(...)):
    """æ›´æ–°æ™ºèƒ½ Agent é…ç½®"""
    if not AGENT_AVAILABLE:
        raise HTTPException(status_code=503, detail="æ™ºèƒ½ Agent æ¨¡å—ä¸å¯ç”¨")

    min_characters = data.get("min_characters", 10)
    silence_threshold = data.get("silence_threshold", 2)
    model_name = data.get("model_name")

    # Update thresholds
    trigger_manager.set_thresholds(min_characters, silence_threshold)

    # Update config file
    config_data = load_config()
    agent_config = config_data.get("agent_config", {})
    agent_config.update({
        "min_characters": min_characters,
        "silence_threshold": silence_threshold,
        "model_name": model_name
    })
    config_data["agent_config"] = agent_config
    save_config(config_data)

    # Reload agent if model changed
    if model_name and AGENT_AVAILABLE:
        model_config = next(
            (c for c in config_data.get("configs", []) if c["name"] == model_name),
            None
        )
        if model_config:
            model_config['model_type'] = 'api'
            agent_manager.load_agent(agent_config, model_config)

    return {"status": "success", "config": agent_config}

@app.post("/api/agent/analyze")
async def manual_analyze(data: dict = Body(...)):
    """æ‰‹åŠ¨è§¦å‘æ™ºèƒ½åˆ†æ"""
    if not AGENT_AVAILABLE:
        raise HTTPException(status_code=503, detail="æ™ºèƒ½ Agent æ¨¡å—ä¸å¯ç”¨")

    messages = data.get("messages", [])
    speaker_name = data.get("speaker_name", "ç”¨æˆ·")

    result = await agent_manager.analyze_conversation(messages, speaker_name)
    return result

@app.get("/api/protagonist")
async def get_protagonist():
    """è·å–å½“å‰ä¸»äººå…¬é…ç½®"""
    config_data = load_config()
    protagonist = config_data.get("protagonist", "")
    return {"protagonist": protagonist}

@app.post("/api/protagonist")
async def set_protagonist_endpoint(data: dict = Body(...)):
    """è®¾ç½®ä¸»äººå…¬"""
    if not AGENT_AVAILABLE:
        raise HTTPException(status_code=503, detail="æ™ºèƒ½ Agent æ¨¡å—ä¸å¯ç”¨")
    
    protagonist = data.get("protagonist", "").strip()
    
    # æ›´æ–°trigger manager
    trigger_manager.set_protagonist(protagonist)
    
    # ä¿å­˜åˆ°é…ç½®æ–‡ä»¶
    config_data = load_config()
    config_data["protagonist"] = protagonist
    save_config(config_data)
    
    return {"status": "success", "protagonist": protagonist}

@app.post("/api/agent/trigger")
async def trigger_multi_llm(data: dict = Body(...)):
    """æ‰‹åŠ¨è§¦å‘å¤šæ¨¡å‹å…±è¯"""
    messages = data.get("messages", [])
    chat_id = data.get("chat_id")

    # This will be handled by the WebSocket endpoint
    return {
        "status": "triggered",
        "message": "å¤šæ¨¡å‹å…±è¯å·²è§¦å‘",
        "messages": messages,
        "chat_id": chat_id
    }

# --- å£°çº¹ç®¡ç† API ---

@app.get("/api/voiceprints")
async def get_voiceprints():
    """è·å–å£°çº¹åº“åˆ—è¡¨"""
    # å³ä½¿ASRç³»ç»Ÿæœªåˆå§‹åŒ–ï¼Œä¹Ÿèƒ½æŸ¥çœ‹å£°çº¹åˆ—è¡¨
    voiceprint_dir = asr_system.VOICEPRINT_DIR if asr_system else "voiceprints"

    if not os.path.exists(voiceprint_dir):
        return {"voiceprints": []}

    voiceprints = []
    for filename in os.listdir(voiceprint_dir):
        if filename.lower().endswith('.wav'):
            name = os.path.splitext(filename)[0]
            wav_path = os.path.join(voiceprint_dir, filename)
            npy_path = os.path.join(voiceprint_dir, f"{name}.npy")

            # è·å–æ–‡ä»¶å¤§å°
            wav_size = os.path.getsize(wav_path)
            has_embedding = os.path.exists(npy_path)
            embedding_size = os.path.getsize(npy_path) if has_embedding else 0

            # è·å–éŸ³é¢‘æ—¶é•¿ï¼ˆç®€å•ä¼°ç®—ï¼‰
            try:
                import soundfile as sf
                info = sf.info(wav_path)
                duration = round(info.duration, 2)
            except:
                duration = None

            voiceprints.append({
                "name": name,
                "wav_file": filename,
                "wav_size": wav_size,
                "has_embedding": has_embedding,
                "embedding_size": embedding_size,
                "duration": duration,
                "created_time": os.path.getctime(wav_path)
            })

    return {"voiceprints": voiceprints}

@app.post("/api/voiceprints")
async def create_voiceprint(data: dict = Body(...)):
    """å½•åˆ¶å¹¶ä¿å­˜æ–°çš„å£°çº¹"""
    name = data.get("name", "").strip()
    audio_data = data.get("audio_data", "")

    if not name:
        raise HTTPException(status_code=400, detail="è¯·è¾“å…¥è¯´è¯äººå§“å")

    if not audio_data:
        raise HTTPException(status_code=400, detail="ç¼ºå°‘éŸ³é¢‘æ•°æ®")

    # æ£€æŸ¥å§“åæ˜¯å¦å·²å­˜åœ¨
    voiceprint_dir = asr_system.VOICEPRINT_DIR if asr_system else "voiceprints"
    wav_path = os.path.join(voiceprint_dir, f"{name}.wav")
    npy_path = os.path.join(voiceprint_dir, f"{name}.npy")

    if os.path.exists(wav_path):
        raise HTTPException(status_code=400, detail=f"è¯´è¯äºº '{name}' å·²å­˜åœ¨")

    try:
        # è§£ç  base64 éŸ³é¢‘æ•°æ®
        # å‰ç«¯å‘é€çš„æ ¼å¼: "data:audio/wav;base64,<base64_data>"
        if ',' in audio_data:
            header, audio_base64 = audio_data.split(',', 1)
        else:
            audio_base64 = audio_data

        audio_bytes = base64.b64decode(audio_base64)

        # ä¿å­˜ä¸ºä¸´æ—¶ WAV æ–‡ä»¶
        temp_path = os.path.join(voiceprint_dir, f"temp_{name}.wav")
        with open(temp_path, 'wb') as f:
            f.write(audio_bytes)

        # æ£€æŸ¥éŸ³é¢‘æ—¶é•¿
        duration = None
        try:
            import soundfile as sf
            info = sf.info(temp_path)
            duration = info.duration

            if duration < 10:
                os.remove(temp_path)
                raise HTTPException(status_code=400, detail=f"å½•åˆ¶æ—¶é•¿å¤ªçŸ­ ({duration:.1f}ç§’)ï¼Œè‡³å°‘éœ€è¦ 10 ç§’")

            if duration > 40:
                os.remove(temp_path)
                raise HTTPException(status_code=400, detail=f"å½•åˆ¶æ—¶é•¿å¤ªé•¿ ({duration:.1f}ç§’)ï¼Œæœ€å¤š 40 ç§’")
        except Exception as e:
            os.remove(temp_path)
            raise HTTPException(status_code=400, detail=f"éŸ³é¢‘éªŒè¯å¤±è´¥: {str(e)}")

        # å¦‚æœ ASR ç³»ç»Ÿå·²åˆå§‹åŒ–ï¼Œä½¿ç”¨å®Œæ•´æµç¨‹
        if asr_system:
            # è½¬æ¢å¹¶ä¿å­˜ä¸ºæ ‡å‡†æ ¼å¼
            asr_system.check_and_convert_audio(temp_path)
            # é‡å‘½åä¸ºæœ€ç»ˆæ–‡ä»¶å
            os.rename(temp_path, wav_path)

            # è®¡ç®—å¹¶ä¿å­˜åµŒå…¥
            print(f"æ­£åœ¨ä¸º {name} è®¡ç®—å£°çº¹åµŒå…¥...")
            embedding = asr_system.extract_embedding(wav_path)
            if embedding is not None:
                import numpy as np
                np.save(npy_path, embedding)
                print(f"âœ… å£°çº¹åµŒå…¥å·²ä¿å­˜: {name}")

                # é‡æ–°åŠ è½½å£°çº¹åº“
                asr_system.load_voiceprints()

                return {
                    "status": "success",
                    "message": f"å£°çº¹å·²ä¿å­˜: {name}",
                    "name": name,
                    "duration": duration,
                    "embedding_saved": True
                }
            else:
                os.remove(wav_path)
                if os.path.exists(npy_path):
                    os.remove(npy_path)
                raise HTTPException(status_code=500, detail="å£°çº¹åµŒå…¥è®¡ç®—å¤±è´¥")
        else:
            # ASR ç³»ç»Ÿæœªåˆå§‹åŒ–ï¼Œåªä¿å­˜ WAV æ–‡ä»¶
            # åç»­ main.py å¯åŠ¨æ—¶ä¼šè‡ªåŠ¨è½¬æ¢
            os.rename(temp_path, wav_path)
            print(f"âš ï¸  ASR ç³»ç»Ÿæœªåˆå§‹åŒ–ï¼Œå·²ä¿å­˜ WAV æ–‡ä»¶: {name}")
            print(f"ğŸ’¡ æç¤ºï¼šä½¿ç”¨æ­£å¸¸æ¨¡å¼å¯åŠ¨æœåŠ¡å™¨æ—¶ä¼šè‡ªåŠ¨è®¡ç®—å£°çº¹åµŒå…¥")

            return {
                "status": "success",
                "message": f"å£°çº¹å·²ä¿å­˜: {name}ï¼ˆä»…éŸ³é¢‘æ–‡ä»¶ï¼ŒåµŒå…¥å°†åœ¨ä¸‹æ¬¡æ­£å¸¸å¯åŠ¨æ—¶è®¡ç®—ï¼‰",
                "name": name,
                "duration": duration,
                "embedding_saved": False
            }

    except HTTPException:
        raise
    except Exception as e:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        temp_path = os.path.join(voiceprint_dir, f"temp_{name}.wav")
        if os.path.exists(temp_path):
            os.remove(temp_path)
        raise HTTPException(status_code=500, detail=f"ä¿å­˜å¤±è´¥: {str(e)}")

@app.delete("/api/voiceprints/{name}")
async def delete_voiceprint(name: str):
    """åˆ é™¤å£°çº¹"""
    # å³ä½¿ASRç³»ç»Ÿæœªåˆå§‹åŒ–ï¼Œä¹Ÿèƒ½åˆ é™¤å£°çº¹æ–‡ä»¶
    name = name.strip()
    if not name:
        raise HTTPException(status_code=400, detail="è¯·æä¾›è¯´è¯äººå§“å")

    voiceprint_dir = asr_system.VOICEPRINT_DIR if asr_system else "voiceprints"
    wav_path = os.path.join(voiceprint_dir, f"{name}.wav")
    npy_path = os.path.join(voiceprint_dir, f"{name}.npy")

    deleted_files = []

    # åˆ é™¤ WAV æ–‡ä»¶
    if os.path.exists(wav_path):
        os.remove(wav_path)
        deleted_files.append(f"{name}.wav")

    # åˆ é™¤ NPY æ–‡ä»¶
    if os.path.exists(npy_path):
        os.remove(npy_path)
        deleted_files.append(f"{name}.npy")

    if not deleted_files:
        raise HTTPException(status_code=404, detail=f"æœªæ‰¾åˆ°è¯´è¯äºº '{name}' çš„å£°çº¹")

    # åªæœ‰åœ¨ASRç³»ç»Ÿåˆå§‹åŒ–æ—¶æ‰é‡æ–°åŠ è½½å£°çº¹åº“
    if asr_system:
        asr_system.load_voiceprints()

    return {
        "status": "success",
        "message": f"å·²åˆ é™¤å£°çº¹: {name}",
        "deleted_files": deleted_files
    }

@app.post("/api/voiceprints/rebuild")
async def rebuild_voiceprints():
    """é‡æ–°è®¡ç®—æ‰€æœ‰å£°çº¹åµŒå…¥"""
    if not asr_system:
        return {
            "status": "error",
            "detail": "ASR ç³»ç»Ÿæœªåˆå§‹åŒ–ï¼Œæ— æ³•é‡æ–°è®¡ç®—åµŒå…¥ã€‚",
            "message": "è¯·ä½¿ç”¨æ­£å¸¸æ¨¡å¼å¯åŠ¨æœåŠ¡å™¨ï¼ˆä¸ä½¿ç”¨ --no å‚æ•°ï¼‰"
        }

    try:
        asr_system.load_voiceprints()
        return {
            "status": "success",
            "message": "å£°çº¹åµŒå…¥é‡æ–°è®¡ç®—å®Œæˆ",
            "count": len(asr_system.speakers)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"é‡æ–°è®¡ç®—å¤±è´¥: {str(e)}")

@app.get("/api/voiceprint/audio/{name}")
async def get_voiceprint_audio(name: str):
    """è·å–å£°çº¹éŸ³é¢‘æ–‡ä»¶"""
    # å³ä½¿ASRç³»ç»Ÿæœªåˆå§‹åŒ–ï¼Œä¹Ÿèƒ½æä¾›éŸ³é¢‘æ–‡ä»¶
    # è§£ç URLç¼–ç çš„åå­—
    name = name.strip()
    if not name:
        raise HTTPException(status_code=400, detail="è¯·æä¾›è¯´è¯äººå§“å")

    voiceprint_dir = asr_system.VOICEPRINT_DIR if asr_system else "voiceprints"
    wav_path = os.path.join(voiceprint_dir, f"{name}.wav")

    if not os.path.exists(wav_path):
        raise HTTPException(status_code=404, detail=f"æœªæ‰¾åˆ°å£°çº¹æ–‡ä»¶: {name}")

    # è¿”å›éŸ³é¢‘æ–‡ä»¶
    from fastapi.responses import FileResponse
    return FileResponse(
        wav_path,
        media_type='audio/wav',
        filename=f"{name}.wav"
    )

@app.websocket("/ws/llm")
async def llm_websocket(websocket: WebSocket):
    await llm_manager.connect(websocket)

    # Reload config on connection to ensure we have the latest
    current_data = load_config()
    curr_name = current_data.get("current_config")
    curr_conf = next((c for c in current_data.get("configs", []) if c["name"] == curr_name), None)

    if curr_conf:
        llm_client.update_config(
            api_key=curr_conf.get("api_key"),
            base_url=curr_conf.get("base_url"),
            model=curr_conf.get("model")
        )

    try:
        while True:
            data = await websocket.receive_json()

            # å¤„ç†æ™ºèƒ½åˆ†æè§¦å‘æ¶ˆæ¯
            if data.get("type") == "agent_triggered":
                print(f"[æ™ºèƒ½åˆ†æ] WebSocket æ”¶åˆ°è§¦å‘æ¶ˆæ¯")
                messages = data.get("messages", [])
                chat_id = data.get("chat_id")
                is_multi_llm = True

                # ç›´æ¥å¤„ç†å¤šæ¨¡å‹æ¨¡å¼
                await handle_multi_llm_request(websocket, messages, chat_id)
                continue

            # data format: { "messages": [...], "chat_id": "...", "is_multi_llm": bool }
            messages = data.get("messages", [])
            chat_id = data.get("chat_id")
            is_multi_llm = data.get("is_multi_llm", False)

            # Add system prompt if not present or just ensure it's there
            if not messages or messages[0].get("role") != "system":
                 messages.insert(0, {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªAiåŠ©æ‰‹å¸®åŠ©ç”¨æˆ·ï¼Œå¹¶ä¸”åˆ†æèŠå¤©è®°å½•"})

            if is_multi_llm:
                # --- Multi-LLM Mode ---
                config_data = load_config()
                active_names = config_data.get("multi_llm_active_names", [])
                configs = config_data.get("configs", [])
                
                active_configs = [c for c in configs if c["name"] in active_names]
                
                if not active_configs:
                     await websocket.send_json({"type": "error", "content": "æœªé€‰æ‹©ä»»ä½•æ¨¡å‹åŠ å…¥é›†ç¾¤ (è¯·åœ¨è®¾ç½®ä¸­å‹¾é€‰)"})
                     continue
                
                # Prepare tasks
                async def stream_one(conf):
                    name = conf["name"]
                    try:
                        client = LLMClient(conf["api_key"], conf["base_url"], conf["model"])
                        
                        # Handle separate system prompt
                        current_messages = [m.copy() for m in messages] # Deep copyish
                        config_prompt = conf.get("system_prompt", "")
                        
                        if config_prompt:
                            # Replace or insert system prompt
                            sys_idx = next((i for i, m in enumerate(current_messages) if m["role"] == "system"), -1)
                            if sys_idx != -1:
                                current_messages[sys_idx]["content"] = config_prompt
                            else:
                                current_messages.insert(0, {"role": "system", "content": config_prompt})
                        
                        full_resp = ""
                        async for chunk in client.chat_stream(current_messages):
                            await websocket.send_json({
                                "type": "chunk",
                                "model": name,
                                "content": chunk
                            })
                            full_resp += chunk
                        
                        await websocket.send_json({"type": "done_one", "model": name})
                        return name, full_resp
                    except Exception as e:
                        err_msg = f"Error: {str(e)}"
                        await websocket.send_json({"type": "error", "content": f"[{name}] {err_msg}"})
                        return name, f"[Error] {err_msg}"

                # Run all concurrently
                tasks = [stream_one(c) for c in active_configs]
                results = await asyncio.gather(*tasks)
                
                await websocket.send_json({"type": "done_all"})
                
                # Save to history
                if chat_id:
                    # Append all responses
                    for name, text in results:
                        messages.append({"role": "assistant", "content": f"**{name}**:\n{text}"})
                    chat_manager.update_chat_messages(chat_id, messages)

            else:
                # --- Single LLM Mode (Original Logic) ---
                response_text = ""
                try:
                    # Check if client is ready
                    if not llm_client.client:
                         await websocket.send_json({"type": "error", "content": "LLM Client not initialized. Please check settings."})
                         continue
    
                    async for chunk in llm_client.chat_stream(messages):
                        await websocket.send_json({"type": "chunk", "content": chunk})
                        response_text += chunk
    
                    await websocket.send_json({"type": "done", "full_text": response_text})
    
                    # Save to chat history if chat_id is provided
                    if chat_id:
                        messages.append({"role": "assistant", "content": response_text})
                        chat_manager.update_chat_messages(chat_id, messages)
    
                except Exception as e:
                    print(f"LLM Stream Error: {e}")
                    await websocket.send_json({"type": "error", "content": f"Stream Error: {str(e)}"})

    except WebSocketDisconnect:
        print("LLM WebSocket disconnected")
        llm_manager.disconnect(websocket)
    except Exception as e:
        print(f"LLM WebSocket Fatal Error: {e}")
        traceback.print_exc()
        llm_manager.disconnect(websocket)

if __name__ == "__main__":
    import uvicorn

    # Print startup banner
    print("=" * 60)
    print("ğŸš€ AST å®æ—¶è¯­éŸ³è½¬æ–‡æœ¬ä¸å¤§æ¨¡å‹åˆ†æç³»ç»Ÿ")
    print("=" * 60)
    print(f"[é…ç½®] ASR ç³»ç»Ÿ: {'âœ… å¯ç”¨' if not args.no_asr else 'âŒ ç¦ç”¨ (--no-asr)'}")
    print(f"[é…ç½®] LLM å®¢æˆ·ç«¯: âœ… å¯ç”¨")
    print(f"[é…ç½®] æœåŠ¡åœ°å€: http://{args.host}:{args.port}")
    print("=" * 60)
    print("")

    uvicorn.run(app, host=args.host, port=args.port)
